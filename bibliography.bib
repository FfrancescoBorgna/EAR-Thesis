
@online{examplewebsite,
  author        = {Wolf and Dewitt},
  note          = {2000; McGlone, 2004},
}
@online{sfm_matlab,
  note          = {Mathworks 2023},
  url           = {https://www.mathworks.com/help/vision/ug/structure-from-motion.html#:~:text=Structure%20from%20motion%20(SfM)%20is,localization%20and%20mapping%20(vSLAM).},
}
@online{open_cv,
  note          = {OpenCV 2024},
  url           = {https://docs.opencv.org/4.x/df/d54/tutorial_py_features_meaning.html},
}
@Book{Hartley2004, 
    author = "Hartley, R.~I. and Zisserman, A.",
    title = "Multiple View Geometry in Computer Vision",
    edition = "Second",
    year = "2004",
    publisher = "Cambridge University Press, ISBN: 0521540518"
}
@online{colmap,
  note = "Colmap 2024",
  url = "https://colmap.github.io/index.html",
}
@inproceedings{schoenberger2016sfm,
    author={Sch\"{o}nberger, Johannes Lutz and Frahm, Jan-Michael},
    title={Structure-from-Motion Revisited},
    booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2016},
}

@inproceedings{schoenberger2016mvs,
    author={Sch\"{o}nberger, Johannes Lutz and Zheng, Enliang and Pollefeys, Marc and Frahm, Jan-Michael},
    title={Pixelwise View Selection for Unstructured Multi-View Stereo},
    booktitle={European Conference on Computer Vision (ECCV)},
    year={2016},
}
@ARTICLE {Ranftl2022,
    author  = "Ren\'{e} Ranftl and Katrin Lasinger and David Hafner and Konrad Schindler and Vladlen Koltun",
    title   = "Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-Shot Cross-Dataset Transfer",
    journal = "IEEE Transactions on Pattern Analysis and Machine Intelligence",
    year    = "2022",
    volume  = "44",
    number  = "3"
}
@article{Ranftl2021,
	author    = {Ren\'{e} Ranftl and Alexey Bochkovskiy and Vladlen Koltun},
	title     = {Vision Transformers for Dense Prediction},
	journal   = {ICCV},
	year      = {2021},
}

@article{neuraldiff,
  author       = {Vadim Tschernezki and
                  Diane Larlus and
                  Andrea Vedaldi},
  title        = {NeuralDiff: Segmenting 3D objects that move in egocentric videos},
  journal      = {CoRR},
  volume       = {abs/2110.09936},
  year         = {2021},
  url          = {https://arxiv.org/abs/2110.09936},
  eprinttype    = {arXiv},
  eprint       = {2110.09936},
  timestamp    = {Mon, 25 Oct 2021 20:07:12 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2110-09936.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{Lowe04_SIFT,
  author    = {David G. Lowe},
  title     = {Distinctive Image Features from Scale-Invariant Keypoints},
  journal   = {International Journal of Computer Vision},
  volume    = {60},
  number    = {2},
  pages     = {91--110},
  year      = {2004},
  doi       = {10.1023/B:VISI.0000029664.99615.94},
  url       = {http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf},
}
@article{BAY_SURF,
title = {Speeded-Up Robust Features (SURF)},
journal = {Computer Vision and Image Understanding},
volume = {110},
number = {3},
pages = {346-359},
year = {2008},
note = {Similarity Matching in Computer Vision and Multimedia},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2007.09.014},
url = {https://www.sciencedirect.com/science/article/pii/S1077314207001555},
author = {Herbert Bay and Andreas Ess and Tinne Tuytelaars and Luc {Van Gool}},
keywords = {Interest points, Local features, Feature description, Camera calibration, Object recognition},
abstract = {This article presents a novel scale- and rotation-invariant detector and descriptor, coined SURF (Speeded-Up Robust Features). SURF approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster. This is achieved by relying on integral images for image convolutions; by building on the strengths of the leading existing detectors and descriptors (specifically, using a Hessian matrix-based measure for the detector, and a distribution-based descriptor); and by simplifying these methods to the essential. This leads to a combination of novel detection, description, and matching steps. The paper encompasses a detailed description of the detector and descriptor and then explores the effects of the most important parameters. We conclude the article with SURF’s application to two challenging, yet converse goals: camera calibration as a special case of image registration, and object recognition. Our experiments underline SURF’s usefulness in a broad range of topics in computer vision.}
}
@InProceedings{Brief,
author="Calonder, Michael
and Lepetit, Vincent
and Strecha, Christoph
and Fua, Pascal",
editor="Daniilidis, Kostas
and Maragos, Petros
and Paragios, Nikos",
title="BRIEF: Binary Robust Independent Elementary Features",
booktitle="Computer Vision -- ECCV 2010",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="778--792",
abstract="We propose to use binary strings as an efficient feature point descriptor, which we call BRIEF.We show that it is highly discriminative even when using relatively few bits and can be computed using simple intensity difference tests. Furthermore, the descriptor similarity can be evaluated using the Hamming distance, which is very efficient to compute, instead of the L2 norm as is usually done.",
isbn="978-3-642-15561-1"
}
@INPROCEEDINGS{ORB,
  author={Rublee, Ethan and Rabaud, Vincent and Konolige, Kurt and Bradski, Gary},
  booktitle={2011 International Conference on Computer Vision}, 
  title={ORB: An efficient alternative to SIFT or SURF}, 
  year={2011},
  volume={},
  number={},
  pages={2564-2571},
  doi={10.1109/ICCV.2011.6126544}}

@INPROCEEDINGS{EPICKITCHENS,
   title={Scaling Egocentric Vision: The EPIC-KITCHENS Dataset},
   author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria  and Fidler, Sanja and 
           Furnari, Antonino and Kazakos, Evangelos and Moltisanti, Davide and Munro, Jonathan 
           and Perrett, Toby and Price, Will and Wray, Michael},
   booktitle={European Conference on Computer Vision (ECCV)},
   year={2018}
   }
@article{residualImage,
  author       = {Kaiming He and
                  Xiangyu Zhang and
                  Shaoqing Ren and
                  Jian Sun},
  title        = {Deep Residual Learning for Image Recognition},
  journal      = {CoRR},
  volume       = {abs/1512.03385},
  year         = {2015},
  url          = {http://arxiv.org/abs/1512.03385},
  eprinttype    = {arXiv},
  eprint       = {1512.03385},
  timestamp    = {Wed, 25 Jan 2023 11:01:16 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/HeZRS15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{fasterRCNN,
  author       = {Shaoqing Ren and
                  Kaiming He and
                  Ross B. Girshick and
                  Jian Sun},
  title        = {Faster {R-CNN:} Towards Real-Time Object Detection with Region Proposal
                  Networks},
  journal      = {CoRR},
  volume       = {abs/1506.01497},
  year         = {2015},
  url          = {http://arxiv.org/abs/1506.01497},
  eprinttype    = {arXiv},
  eprint       = {1506.01497},
  timestamp    = {Mon, 13 Aug 2018 16:46:02 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/RenHG015.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{captioning,
  author       = {Andrej Karpathy and
                  Li Fei{-}Fei},
  title        = {Deep Visual-Semantic Alignments for Generating Image Descriptions},
  journal      = {CoRR},
  volume       = {abs/1412.2306},
  year         = {2014},
  url          = {http://arxiv.org/abs/1412.2306},
  eprinttype    = {arXiv},
  eprint       = {1412.2306},
  timestamp    = {Wed, 15 Sep 2021 14:13:01 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/KarpathyF14.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@InProceedings{vqa,
author = {Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C. Lawrence and Parikh, Devi},
title = {VQA: Visual Question Answering},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
month = {December},
year = {2015}
}
@article{pascalImage,
  added-at = {2020-05-23T11:30:44.000+0200},
  author = {Everingham, Mark and Gool, Luc Van and Williams, Christopher K. I. and Winn, John M. and Zisserman, Andrew},
  biburl = {https://www.bibsonomy.org/bibtex/2cb5ac4f22faf09897fd86076931d682b/jan.hofmann1},
  ee = {https://www.wikidata.org/entity/Q56594395},
  interhash = {8d7846ab0aa897ffead1e7abf2dfba3e},
  intrahash = {cb5ac4f22faf09897fd86076931d682b},
  journal = {Int. J. Comput. Vis.},
  keywords = {thema:pyramid_scene_parsing},
  number = 2,
  pages = {303-338},
  timestamp = {2020-05-23T11:30:44.000+0200},
  title = {The Pascal Visual Object Classes (VOC) Challenge.},
  url = {http://dblp.uni-trier.de/db/journals/ijcv/ijcv88.html#EveringhamGWWZ10},
  volume = 88,
  year = 2010
}
@INPROCEEDINGS{imagenet,
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={ImageNet: A large-scale hierarchical image database}, 
  year={2009},
  volume={},
  number={},
  pages={248-255},
  keywords={Large-scale systems;Image databases;Explosions;Internet;Robustness;Information retrieval;Image retrieval;Multimedia databases;Ontologies;Spine},
  doi={10.1109/CVPR.2009.5206848}}

  @article{COCO,
  author       = {Tsung{-}Yi Lin and
                  Michael Maire and
                  Serge J. Belongie and
                  Lubomir D. Bourdev and
                  Ross B. Girshick and
                  James Hays and
                  Pietro Perona and
                  Deva Ramanan and
                  Piotr Doll{\'{a}}r and
                  C. Lawrence Zitnick},
  title        = {Microsoft {COCO:} Common Objects in Context},
  journal      = {CoRR},
  volume       = {abs/1405.0312},
  year         = {2014},
  url          = {http://arxiv.org/abs/1405.0312},
  eprinttype    = {arXiv},
  eprint       = {1405.0312},
  timestamp    = {Mon, 13 Aug 2018 16:48:13 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/LinMBHPRDZ14.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@INPROCEEDINGS{ADE20K,
  author={Zhou, Bolei and Zhao, Hang and Puig, Xavier and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Scene Parsing through ADE20K Dataset}, 
  year={2017},
  volume={},
  number={},
  pages={5122-5130},
  keywords={Image segmentation;Semantics;Sun;Labeling;Visualization;Neural networks;Computer vision},
  doi={10.1109/CVPR.2017.544}}

@article{somethingSomething,
  author       = {Raghav Goyal and
                  Samira Ebrahimi Kahou and
                  Vincent Michalski and
                  Joanna Materzynska and
                  Susanne Westphal and
                  Heuna Kim and
                  Valentin Haenel and
                  Ingo Fr{\"{u}}nd and
                  Peter Yianilos and
                  Moritz Mueller{-}Freitag and
                  Florian Hoppe and
                  Christian Thurau and
                  Ingo Bax and
                  Roland Memisevic},
  title        = {The "something something" video database for learning and evaluating
                  visual common sense},
  journal      = {CoRR},
  volume       = {abs/1706.04261},
  year         = {2017},
  url          = {http://arxiv.org/abs/1706.04261},
  eprinttype    = {arXiv},
  eprint       = {1706.04261},
  timestamp    = {Mon, 13 Aug 2018 16:48:38 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/GoyalKMMWKHFYMH17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{yt,
  author       = {Sami Abu{-}El{-}Haija and
                  Nisarg Kothari and
                  Joonseok Lee and
                  Paul Natsev and
                  George Toderici and
                  Balakrishnan Varadarajan and
                  Sudheendra Vijayanarasimhan},
  title        = {YouTube-8M: {A} Large-Scale Video Classification Benchmark},
  journal      = {CoRR},
  volume       = {abs/1609.08675},
  year         = {2016},
  url          = {http://arxiv.org/abs/1609.08675},
  eprinttype    = {arXiv},
  eprint       = {1609.08675},
  timestamp    = {Sun, 02 Oct 2022 15:31:42 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/Abu-El-HaijaKLN16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{movieBench,
  author       = {Anna Rohrbach and
                  Marcus Rohrbach and
                  Niket Tandon and
                  Bernt Schiele},
  title        = {A Dataset for Movie Description},
  journal      = {CoRR},
  volume       = {abs/1501.02530},
  year         = {2015},
  url          = {http://arxiv.org/abs/1501.02530},
  eprinttype    = {arXiv},
  eprint       = {1501.02530},
  timestamp    = {Mon, 13 Aug 2018 16:47:07 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/RohrbachRTS15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{movieQA,
  author       = {Makarand Tapaswi and
                  Yukun Zhu and
                  Rainer Stiefelhagen and
                  Antonio Torralba and
                  Raquel Urtasun and
                  Sanja Fidler},
  title        = {MovieQA: Understanding Stories in Movies through Question-Answering},
  journal      = {CoRR},
  volume       = {abs/1512.02902},
  year         = {2015},
  url          = {http://arxiv.org/abs/1512.02902},
  eprinttype    = {arXiv},
  eprint       = {1512.02902},
  timestamp    = {Mon, 13 Aug 2018 16:45:57 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/TapaswiZSTUF15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{vlogs,
  author       = {David F. Fouhey and
                  Weicheng Kuo and
                  Alexei A. Efros and
                  Jitendra Malik},
  title        = {From Lifestyle Vlogs to Everyday Interactions},
  journal      = {CoRR},
  volume       = {abs/1712.02310},
  year         = {2017},
  url          = {http://arxiv.org/abs/1712.02310},
  eprinttype    = {arXiv},
  eprint       = {1712.02310},
  timestamp    = {Mon, 13 Aug 2018 16:48:20 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1712-02310.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{charades,
  author       = {Gunnar A. Sigurdsson and
                  G{\"{u}}l Varol and
                  Xiaolong Wang and
                  Ali Farhadi and
                  Ivan Laptev and
                  Abhinav Gupta},
  title        = {Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding},
  journal      = {CoRR},
  volume       = {abs/1604.01753},
  year         = {2016},
  url          = {http://arxiv.org/abs/1604.01753},
  eprinttype    = {arXiv},
  eprint       = {1604.01753},
  timestamp    = {Fri, 05 Apr 2019 07:29:46 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/SigurdssonVWFLG16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@ARTICLE{EK100,
           title={Rescaling Egocentric Vision: Collection, Pipeline and Challenges for EPIC-KITCHENS-100},
           author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria and Furnari, Antonino 
           and Ma, Jian and Kazakos, Evangelos and Moltisanti, Davide and Munro, Jonathan 
           and Perrett, Toby and Price, Will and Wray, Michael},
           journal   = {International Journal of Computer Vision (IJCV)},
           year      = {2022},
           volume = {130},
           pages = {33–55},
           Url       = {https://doi.org/10.1007/s11263-021-01531-2}
} 
@misc{Word2Vec,
      title={Efficient Estimation of Word Representations in Vector Space}, 
      author={Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
      year={2013},
      eprint={1301.3781},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{visor35,
      title={Understanding Human Hands in Contact at Internet Scale}, 
      author={Dandan Shan and Jiaqi Geng and Michelle Shu and David F. Fouhey},
      year={2020},
      eprint={2006.06669},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{visor5,
      title={Large-scale interactive object segmentation with human annotators}, 
      author={Rodrigo Benenson and Stefan Popov and Vittorio Ferrari},
      year={2019},
      eprint={1903.10830},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{nerf,
      title={NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis}, 
      author={Ben Mildenhall and Pratul P. Srinivasan and Matthew Tancik and Jonathan T. Barron and Ravi Ramamoorthi and Ren Ng},
      year={2020},
      eprint={2003.08934},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{neuraldiff,
      title={NeuralDiff: Segmenting 3D objects that move in egocentric videos}, 
      author={Vadim Tschernezki and Diane Larlus and Andrea Vedaldi},
      year={2021},
      eprint={2110.09936},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{nerfw,
      title={NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections}, 
      author={Ricardo Martin-Brualla and Noha Radwan and Mehdi S. M. Sajjadi and Jonathan T. Barron and Alexey Dosovitskiy and Daniel Duckworth},
      year={2021},
      eprint={2008.02268},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{Tnerf,
      title={Monocular Dynamic View Synthesis: A Reality Check}, 
      author={Hang Gao and Ruilong Li and Shubham Tulsiani and Bryan Russell and Angjoo Kanazawa},
      year={2022},
      eprint={2210.13445},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}@misc{MG,
      title={Self-supervised Video Object Segmentation by Motion Grouping}, 
      author={Charig Yang and Hala Lamdouar and Erika Lu and Andrew Zisserman and Weidi Xie},
      year={2021},
      eprint={2104.07658},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@incollection{bundle,
  author    = {Andrew W. Fitzgibbon and
               Simon W. Bowman and
               Andrew Zisserman and
               Mark A. Fischler},
  title     = {Bundle Adjustment – A Modern Synthesis},
  booktitle = {Vision Algorithms: Theory and Practice},
  publisher = {Springer-Verlag},
  year      = {2000},
  volume    = {1883},
  series    = {LNCS},
  pages     = {298--372},
}

@ARTICLE{DIML,
  author={Kim, Youngjung and Jung, Hyungjoo and Min, Dongbo and Sohn, Kwanghoon},
  journal={IEEE Transactions on Image Processing}, 
  title={Deep Monocular Depth Estimation via Integration of Global and Local Predictions}, 
  year={2018},
  volume={27},
  number={8},
  pages={4131-4144},
  keywords={Estimation;Predictive models;Databases;Training;Optimization;Measurement;Computational modeling;Depth estimation;2D-to-3D conversion;non-parametric sampling;convolutional neural networks;RGB-D database},
  doi={10.1109/TIP.2018.2836318}}
@misc{megadepth,
      title={MegaDepth: Learning Single-View Depth Prediction from Internet Photos}, 
      author={Zhengqi Li and Noah Snavely},
      year={2018},
      eprint={1804.00607},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@INPROCEEDINGS{redweb,
  author={Xian, Ke and Shen, Chunhua and Cao, Zhiguo and Lu, Hao and Xiao, Yang and Li, Ruibo and Luo, Zhenbo},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  title={Monocular Relative Depth Perception with Web Stereo Data Supervision}, 
  year={2018},
  volume={},
  number={},
  pages={311-320},
  keywords={Training;Measurement;Task analysis;Semantics;Estimation;Image segmentation;Network architecture},
  doi={10.1109/CVPR.2018.00040}}
@misc{wsvd,
      title={Web Stereo Video Supervision for Depth Prediction from Dynamic Scenes}, 
      author={Chaoyang Wang and Simon Lucey and Federico Perazzi and Oliver Wang},
      year={2019},
      eprint={1904.11112},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{diw,
      title={Single-Image Depth Perception in the Wild}, 
      author={Weifeng Chen and Zhao Fu and Dawei Yang and Jia Deng},
      year={2017},
      eprint={1604.03901},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@INPROCEEDINGS{eth3d,
  author={Schöps, Thomas and Schönberger, Johannes L. and Galliani, Silvano and Sattler, Torsten and Schindler, Konrad and Pollefeys, Marc and Geiger, Andreas},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={A Multi-view Stereo Benchmark with High-Resolution Images and Multi-camera Videos}, 
  year={2017},
  volume={},
  number={},
  pages={2538-2547},
  keywords={Benchmark testing;Cameras;Three-dimensional displays;Lasers;Image resolution;Videos;Robot vision systems},
  doi={10.1109/CVPR.2017.272}}
@InProceedings{sintel,
author="Butler, Daniel J.
and Wulff, Jonas
and Stanley, Garrett B.
and Black, Michael J.",
editor="Fitzgibbon, Andrew
and Lazebnik, Svetlana
and Perona, Pietro
and Sato, Yoichi
and Schmid, Cordelia",
title="A Naturalistic Open Source Movie for Optical Flow Evaluation",
booktitle="Computer Vision -- ECCV 2012",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="611--625",
abstract="Ground truth optical flow is difficult to measure in real scenes with natural motion. As a result, optical flow data sets are restricted in terms of size, complexity, and diversity, making optical flow algorithms difficult to train and test on realistic data. We introduce a new optical flow data set derived from the open source 3D animated short film Sintel. This data set has important features not present in the popular Middlebury flow evaluation: long sequences, large motions, specular reflections, motion blur, defocus blur, and atmospheric effects. Because the graphics data that generated the movie is open source, we are able to render scenes under conditions of varying complexity to evaluate where existing flow algorithms fail. We evaluate several recent optical flow algorithms and find that current highly-ranked methods on the Middlebury evaluation have difficulty with this more complex data set suggesting further research on optical flow estimation is needed. To validate the use of synthetic data, we compare the image- and flow-statistics of Sintel to those of real films and videos and show that they are similar. The data set, metrics, and evaluation website are publicly available.",
isbn="978-3-642-33783-3"
}

@INPROCEEDINGS{kitti,
  author={Geiger, Andreas and Lenz, Philip and Urtasun, Raquel},
  booktitle={2012 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={Are we ready for autonomous driving? The KITTI vision benchmark suite}, 
  year={2012},
  volume={},
  number={},
  pages={3354-3361},
  keywords={Benchmark testing;Cameras;Optical imaging;Visualization;Optical sensors;Measurement},
  doi={10.1109/CVPR.2012.6248074}}
@InProceedings{nyudv2,
author="Silberman, Nathan
and Hoiem, Derek
and Kohli, Pushmeet
and Fergus, Rob",
editor="Fitzgibbon, Andrew
and Lazebnik, Svetlana
and Perona, Pietro
and Sato, Yoichi
and Schmid, Cordelia",
title="Indoor Segmentation and Support Inference from RGBD Images",
booktitle="Computer Vision -- ECCV 2012",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="746--760",
abstract="We present an approach to interpret the major surfaces, objects, and support relations of an indoor scene from an RGBD image. Most existing work ignores physical interactions or is applied only to tidy rooms and hallways. Our goal is to parse typical, often messy, indoor scenes into floor, walls, supporting surfaces, and object regions, and to recover support relationships. One of our main interests is to better understand how 3D cues can best inform a structured 3D interpretation. We also contribute a novel integer programming formulation to infer physical support relations. We offer a new dataset of 1449 RGBD images, capturing 464 diverse indoor scenes, with detailed annotations. Our experiments demonstrate our ability to infer support relations in complex scenes and verify that our 3D scene cues and inferred support lead to better object segmentation.",
isbn="978-3-642-33715-4"
}
@INPROCEEDINGS{tum_rgbd,
  author={Sturm, Jürgen and Engelhard, Nikolas and Endres, Felix and Burgard, Wolfram and Cremers, Daniel},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={A benchmark for the evaluation of RGB-D SLAM systems}, 
  year={2012},
  volume={},
  number={},
  pages={573-580},
  keywords={Cameras;Simultaneous localization and mapping;Calibration;Trajectory;Visualization},
  doi={10.1109/IROS.2012.6385773}}
@misc{visor,
      title={EPIC-KITCHENS VISOR Benchmark: VIdeo Segmentations and Object Relations}, 
      author={Ahmad Darkhalil and Dandan Shan and Bin Zhu and Jian Ma and Amlan Kar and Richard Higgins and Sanja Fidler and David Fouhey and Dima Damen},
      year={2022},
      eprint={2209.13064},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@url{CVPRtutorial,
  url= {https://justusthies.github.io/posts/neuralrenderingtutorial_cvpr/#:~:text=Neural%20rendering%20is%20a%20new,%2C%20appearance%2C%20and%20semantic%20structure}
}
@misc{nerf15,
      title={Local Implicit Grid Representations for 3D Scenes}, 
      author={Chiyu Max Jiang and Avneesh Sud and Ameesh Makadia and Jingwei Huang and Matthias Nießner and Thomas Funkhouser},
      year={2020},
      eprint={2003.08981},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{nerf32,
      title={DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation}, 
      author={Jeong Joon Park and Peter Florence and Julian Straub and Richard Newcombe and Steven Lovegrove},
      year={2019},
      eprint={1901.05103},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{nerf11,
      title={Local Deep Implicit Functions for 3D Shape}, 
      author={Kyle Genova and Forrester Cole and Avneesh Sud and Aaron Sarna and Thomas Funkhouser},
      year={2020},
      eprint={1912.06126},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{nerf27,
      title={Occupancy Networks: Learning 3D Reconstruction in Function Space}, 
      author={Lars Mescheder and Michael Oechsle and Michael Niemeyer and Sebastian Nowozin and Andreas Geiger},
      year={2019},
      eprint={1812.03828},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{nerf29,
      title={Differentiable Volumetric Rendering: Learning Implicit 3D Representations without 3D Supervision}, 
      author={Michael Niemeyer and Lars Mescheder and Michael Oechsle and Andreas Geiger},
      year={2020},
      eprint={1912.07372},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{nerf42,
      title={Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations}, 
      author={Vincent Sitzmann and Michael Zollhöfer and Gordon Wetzstein},
      year={2020},
      eprint={1906.01618},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@inproceedings{nerf21, series={SIGGRAPH96}, title={Light field rendering}, url={http://dx.doi.org/10.1145/237170.237199}, DOI={10.1145/237170.237199}, booktitle={Proceedings of the 23rd annual conference on Computer graphics and interactive techniques}, publisher={ACM}, author={Levoy, Marc and Hanrahan, Pat}, year={1996}, month=aug, collection={SIGGRAPH96} }
@article{nerf5,
author = {Gortler, Steven and Grzeszczuk, Radek and Szeliski, Richard and Cohen, Michael},
year = {2001},
month = {08},
pages = {},
title = {The Lumigraph},
volume = {96},
journal = {Proc. of SIGGRAPH 96},
doi = {10.1145/237170.237200}
}
@inproceedings{nerf48,
  title={Let There Be Color! Large-Scale Texturing of 3D Reconstructions},
  author={Michael Waechter and Nils Moehrle and Michael Goesele},
  booktitle={European Conference on Computer Vision},
  year={2014},
  url={https://api.semanticscholar.org/CorpusID:6085476}
}
@article{nerf2,
  title={Unstructured lumigraph rendering},
  author={Chris Buehler and Michael Bosse and Leonard McMillan and Steven J. Gortler and Michael F. Cohen},
  journal={Proceedings of the 28th annual conference on Computer graphics and interactive techniques},
  year={2001},
  url={https://api.semanticscholar.org/CorpusID:215780580}
}
@misc{nerf4,
      title={Learning to Predict 3D Objects with an Interpolation-based Differentiable Renderer}, 
      author={Wenzheng Chen and Jun Gao and Huan Ling and Edward J. Smith and Jaakko Lehtinen and Alec Jacobson and Sanja Fidler},
      year={2019},
      eprint={1908.01210},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{nerf10,
      title={Unsupervised Training for 3D Morphable Model Regression}, 
      author={Kyle Genova and Forrester Cole and Aaron Maschinot and Aaron Sarna and Daniel Vlasic and William T. Freeman},
      year={2018},
      eprint={1806.06098},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{nerf23,
      title={Soft Rasterizer: Differentiable Rendering for Unsupervised Single-View Mesh Reconstruction}, 
      author={Shichen Liu and Weikai Chen and Tianye Li and Hao Li},
      year={2019},
      eprint={1901.05567},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@INPROCEEDINGS{nerf19,
  author={Kutulakos, K.N. and Seitz, S.M.},
  booktitle={Proceedings of the Seventh IEEE International Conference on Computer Vision}, 
  title={A theory of shape by space carving}, 
  year={1999},
  volume={1},
  number={},
  pages={307-314 vol.1},
  keywords={Shape;Layout;Cameras;Read only memory;Electrical capacitance tomography;Computer science;Orbital robotics;Computer vision;Stereo vision;Face detection},
  doi={10.1109/ICCV.1999.791235}}

@misc{nerf9,
      title={DeepView: View Synthesis with Learned Gradient Descent}, 
      author={John Flynn and Michael Broxton and Paul Debevec and Matthew DuVall and Graham Fyffe and Ryan Overbeck and Noah Snavely and Richard Tucker},
      year={2019},
      eprint={1906.07316},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{nerf13,
      title={Single-image Tomography: 3D Volumes from 2D Cranial X-Rays}, 
      author={Philipp Henzler and Volker Rasche and Timo Ropinski and Tobias Ritschel},
      year={2018},
      eprint={1710.04867},
      archivePrefix={arXiv},
      primaryClass={cs.GR}
}
@article{nerf17,
  title={Learning a Multi-View Stereo Machine},
  author={Abhishek Kar and Christian H{\"a}ne and Jitendra Malik},
  journal={ArXiv},
  year={2017},
  volume={abs/1708.05375},
  url={https://api.semanticscholar.org/CorpusID:19285959}
}
@article{nerf16,
  title={Ray tracing volume densities},
  author={James T. Kajiya and Brian Von Herzen},
  journal={Proceedings of the 11th annual conference on Computer graphics and interactive techniques},
  year={1984},
  url={https://api.semanticscholar.org/CorpusID:6722621}
}
@ARTICLE{nerf26,
  author={Max, N.},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Optical models for direct volume rendering}, 
  year={1995},
  volume={1},
  number={2},
  pages={99-108},
  keywords={Optical scattering;Light scattering;X-ray scattering;Stimulated emission;Absorption;Interpolation;Optical computing;Rendering (computer graphics);Grid computing;Computational modeling},
  doi={10.1109/2945.468400}}
@misc{nerf35,
      title={On the Spectral Bias of Neural Networks}, 
      author={Nasim Rahaman and Aristide Baratin and Devansh Arpit and Felix Draxler and Min Lin and Fred A. Hamprecht and Yoshua Bengio and Aaron Courville},
      year={2019},
      eprint={1806.08734},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}
@misc{deepvoxels,
      title={DeepVoxels: Learning Persistent 3D Feature Embeddings}, 
      author={Vincent Sitzmann and Justus Thies and Felix Heide and Matthias Nießner and Gordon Wetzstein and Michael Zollhöfer},
      year={2019},
      eprint={1812.01024},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@inbook{Lambertian,
author = {Koppal, Sanjeev},
year = {2014},
month = {01},
pages = {441-443},
title = {Lambertian Reflectance},
isbn = {978-0-387-30771-8},
doi = {10.1007/978-0-387-31439-6_534}
}
@misc{LLFF,
      title={Local Light Field Fusion: Practical View Synthesis with Prescriptive Sampling Guidelines}, 
      author={Ben Mildenhall and Pratul P. Srinivasan and Rodrigo Ortiz-Cayon and Nima Khademi Kalantari and Ravi Ramamoorthi and Ren Ng and Abhishek Kar},
      year={2019},
      eprint={1905.00889},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{neuralvol,
   title={Neural volumes: learning dynamic renderable volumes from images},
   volume={38},
   ISSN={1557-7368},
   url={http://dx.doi.org/10.1145/3306346.3323020},
   DOI={10.1145/3306346.3323020},
   number={4},
   journal={ACM Transactions on Graphics},
   publisher={Association for Computing Machinery (ACM)},
   author={Lombardi, Stephen and Simon, Tomas and Saragih, Jason and Schwartz, Gabriel and Lehrmann, Andreas and Sheikh, Yaser},
   year={2019},
   month=jul, pages={1–14} }
@misc{srn,
      title={Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations}, 
      author={Vincent Sitzmann and Michael Zollhöfer and Gordon Wetzstein},
      year={2020},
      eprint={1906.01618},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{ego4d,
      title={Ego4D: Around the World in 3,000 Hours of Egocentric Video}, 
      author={Kristen Grauman and Andrew Westbury and Eugene Byrne and Zachary Chavis and Antonino Furnari and Rohit Girdhar and Jackson Hamburger and Hao Jiang and Miao Liu and Xingyu Liu and Miguel Martin and Tushar Nagarajan and Ilija Radosavovic and Santhosh Kumar Ramakrishnan and Fiona Ryan and Jayant Sharma and Michael Wray and Mengmeng Xu and Eric Zhongcong Xu and Chen Zhao and Siddhant Bansal and Dhruv Batra and Vincent Cartillier and Sean Crane and Tien Do and Morrie Doulaty and Akshay Erapalli and Christoph Feichtenhofer and Adriano Fragomeni and Qichen Fu and Abrham Gebreselasie and Cristina Gonzalez and James Hillis and Xuhua Huang and Yifei Huang and Wenqi Jia and Weslie Khoo and Jachym Kolar and Satwik Kottur and Anurag Kumar and Federico Landini and Chao Li and Yanghao Li and Zhenqiang Li and Karttikeya Mangalam and Raghava Modhugu and Jonathan Munro and Tullie Murrell and Takumi Nishiyasu and Will Price and Paola Ruiz Puentes and Merey Ramazanova and Leda Sari and Kiran Somasundaram and Audrey Southerland and Yusuke Sugano and Ruijie Tao and Minh Vo and Yuchen Wang and Xindi Wu and Takuma Yagi and Ziwei Zhao and Yunyi Zhu and Pablo Arbelaez and David Crandall and Dima Damen and Giovanni Maria Farinella and Christian Fuegen and Bernard Ghanem and Vamsi Krishna Ithapu and C. V. Jawahar and Hanbyul Joo and Kris Kitani and Haizhou Li and Richard Newcombe and Aude Oliva and Hyun Soo Park and James M. Rehg and Yoichi Sato and Jianbo Shi and Mike Zheng Shou and Antonio Torralba and Lorenzo Torresani and Mingfei Yan and Jitendra Malik},
      year={2022},
      eprint={2110.07058},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{ndiff_2,
title = {Traditional and recent approaches in background modeling for foreground detection: An overview},
journal = {Computer Science Review},
volume = {11-12},
pages = {31-66},
year = {2014},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2014.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S1574013714000033},
author = {Thierry Bouwmans},
keywords = {Background subtraction, Background modeling, Background initialization, Background maintenance, Foreground detection},
abstract = {Background modeling for foreground detection is often used in different applications to model the background and then detect the moving objects in the scene like in video surveillance. The last decade witnessed very significant publications in this field. Furthermore, several surveys can be found in the literature but none of them addresses an overall review in this field. So, the purpose of this paper is to provide a complete survey of the traditional and recent approaches. First, we categorize the different approaches found in the literature. We have classified them in terms of the mathematical models used and we have discussed them in terms of the critical situations that they claim to handle. Furthermore, we present the available resources, datasets and libraries. Then, we conclude with several promising directions for future research.}
}
@INPROCEEDINGS{ndiff_18,
  author={Mattheus, Jana and Grobler, Hans and Abu-Mahfouz, Adnan M.},
  booktitle={2020 2nd International Multidisciplinary Information Technology and Engineering Conference (IMITEC)}, 
  title={A Review of Motion Segmentation: Approaches and Major Challenges}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  keywords={Manifolds;Computer vision;Motion segmentation;Video surveillance;Trajectory;Video signal processing;Sports;Motion Segmentation;Motion Analysis;Articulated;Non-rigid;Factorization Method;Manifold Clustering;3D Scene Analysis;Computer Vision},
  doi={10.1109/IMITEC50163.2020.9334076}}
@inproceedings{ndiff_41,
author = {Zappella, Luca and Llado, Xavier and Salvi, Joaquim},
year = {2008},
month = {01},
pages = {398-407},
title = {Motion Segmentation: a Review},
volume = {184},
journal = {Frontiers in Artificial Intelligence and Applications},
doi = {10.3233/978-1-58603-925-7-398}
}
@misc{ndiff_17,
      title={NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections}, 
      author={Ricardo Martin-Brualla and Noha Radwan and Mehdi S. M. Sajjadi and Jonathan T. Barron and Alexey Dosovitskiy and Daniel Duckworth},
      year={2021},
      eprint={2008.02268},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{ndiff_36,
      title={FiG-NeRF: Figure-Ground Neural Radiance Fields for 3D Object Category Modelling}, 
      author={Christopher Xie and Keunhong Park and Ricardo Martin-Brualla and Matthew Brown},
      year={2021},
      eprint={2104.08418},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{ndiff_30,
      title={Decomposing 3D Scenes into Objects via Unsupervised Volume Segmentation}, 
      author={Karl Stelzner and Kristian Kersting and Adam R. Kosiorek},
      year={2021},
      eprint={2104.01148},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{ndiff_25,
      title={Nerfies: Deformable Neural Radiance Fields}, 
      author={Keunhong Park and Utkarsh Sinha and Jonathan T. Barron and Sofien Bouaziz and Dan B Goldman and Steven M. Seitz and Ricardo Martin-Brualla},
      year={2021},
      eprint={2011.12948},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{ndiff_15,
      title={Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic Scenes}, 
      author={Zhengqi Li and Simon Niklaus and Noah Snavely and Oliver Wang},
      year={2021},
      eprint={2011.13084},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{ndiff_27,
  title={D-NeRF: Neural Radiance Fields for Dynamic Scenes},
  author={Pumarola, Albert and Corona, Enric and Pons-Moll, Gerard and Moreno-Noguer, Francesc},
  journal={arXiv preprint arXiv:2011.13961},
  year={2020}
}
@misc{ndiff_9,
      title={Dynamic View Synthesis from Dynamic Monocular Video}, 
      author={Chen Gao and Ayush Saraf and Johannes Kopf and Jia-Bin Huang},
      year={2021},
      eprint={2105.06468},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{ndiff_34,
      title={Non-Rigid Neural Radiance Fields: Reconstruction and Novel View Synthesis of a Dynamic Scene From Monocular Video}, 
      author={Edgar Tretschk and Ayush Tewari and Vladislav Golyanik and Michael Zollhöfer and Christoph Lassner and Christian Theobalt},
      year={2021},
      eprint={2012.12247},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{ndiff_1,
      title={It's Moving! A Probabilistic Model for Causal Motion Segmentation in Moving Camera Videos}, 
      author={Pia Bideau and Erik Learned-Miller},
      year={2016},
      eprint={1604.00136},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@InProceedings{ndiff_3,
author="Brox, Thomas
and Malik, Jitendra",
editor="Daniilidis, Kostas
and Maragos, Petros
and Paragios, Nikos",
title="Object Segmentation by Long Term Analysis of Point Trajectories",
booktitle="Computer Vision -- ECCV 2010",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="282--295",
abstract="Unsupervised learning requires a grouping step that defines which data belong together. A natural way of grouping in images is the segmentation of objects or parts of objects. While pure bottom-up segmentation from static cues is well known to be ambiguous at the object level, the story changes as soon as objects move. In this paper, we present a method that uses long term point trajectories based on dense optical flow. Defining pair-wise distances between these trajectories allows to cluster them, which results in temporally consistent segmentations of moving objects in a video shot. In contrast to multi-body factorization, points and even whole objects may appear or disappear during the shot. We provide a benchmark dataset and an evaluation method for this so far uncovered setting.",
isbn="978-3-642-15555-0"
}
@misc{ndiff_38,
      title={Self-supervised Video Object Segmentation by Motion Grouping}, 
      author={Charig Yang and Hala Lamdouar and Erika Lu and Andrew Zisserman and Weidi Xie},
      year={2021},
      eprint={2104.07658},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

