\babel@toc {italian}{}\relax 
\babel@toc {italian}{}\relax 
\babel@toc {italian}{}\relax 
\babel@toc {english}{}\relax 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces \textbf {Top} (left to right): time of day of the recording, pie chart of high-level goals, histogram of sequence durations and dataset logo; \textbf {Bottom}:Wordles of narrations in native languages(English, Italian, Spanish, Greek and Chinese).}}{5}{figure.caption.5}%
\contentsline {figure}{\numberline {1.2}{\ignorespaces Narration Guidelines given to each participant to be followed after the completion of a recording.}}{6}{figure.caption.6}%
\contentsline {figure}{\numberline {1.3}{\ignorespaces Extracts from 6 transcription files in .sbv format}}{6}{figure.caption.7}%
\contentsline {figure}{\numberline {1.4}{\ignorespaces Example of annotated action segments for 2 consecutive actions}}{7}{figure.caption.8}%
\contentsline {figure}{\numberline {1.5}{\ignorespaces Sample Verb and Noun Classes}}{7}{figure.caption.9}%
\contentsline {figure}{\numberline {1.6}{\ignorespaces \textbf {From Top:} Frequency of verb classes in action segments; Frequency of noun clusters in action segments, by category; Frequency of noun clusters in bounding box annotations, by category; Mean and standard deviation of bounding box, by category}}{8}{figure.caption.10}%
\contentsline {figure}{\numberline {1.7}{\ignorespaces Sample consecutive action segments with keyframe object annotations}}{9}{figure.caption.11}%
\contentsline {figure}{\numberline {1.8}{\ignorespaces Sample qualitative results from the challenge's baseline of the Action Recognition Task}}{10}{figure.caption.13}%
\contentsline {figure}{\numberline {1.9}{\ignorespaces Sample qualitative results from the challenge's baseline of the Action Anticipation Task}}{10}{figure.caption.15}%
\contentsline {figure}{\numberline {1.10}{\ignorespaces Sample qualitative results from the challenge's baseline of the Object Detection Task}}{11}{figure.caption.17}%
\contentsline {figure}{\numberline {1.11}{\ignorespaces Annotation pipeline: \textbf {a} narrator, \textbf {b} transcriber \textbf {c} temporal segment annotator and \textbf {d} dependency parser. Red arrows show AMT crowdsourcing of annotations.}}{13}{figure.caption.18}%
\contentsline {figure}{\numberline {1.12}{\ignorespaces Comparing non-stop narrations (blue) to 'pause-and-talk' narrations (red). Right: timestsamps (dots) and segments (bars) for two sample sequences. "pause-and-talk" captures all actions including short ones. Black frames depict missed actions.}}{14}{figure.caption.23}%
\contentsline {figure}{\numberline {1.13}{\ignorespaces \textbf {Dynamic New View Synthesis}. I report an example of the output for the three different methods used: NeRF-W, T-NeRF+ and NeuralDiff. We can see how the initial labelling of difficulty for frames was actually accurate as the reconstructions struggle with Hard frames.}}{19}{figure.caption.31}%
\contentsline {figure}{\numberline {1.14}{\ignorespaces \textbf {UDOS.} Here is reported the comparison of the different methods' output. The 2D based perform very good on dynamic objects, while 3D methods struggle a bit but can detect even semi-static objects.}}{20}{figure.caption.33}%
\contentsline {figure}{\numberline {1.15}{\ignorespaces \textbf {VOS.} Here is reported the comparison of the two different methods. The 3D method is clearly beter having as output something really close to the groundtruth. The 2D method instead is performing poorly.}}{21}{figure.caption.36}%
\contentsline {figure}{\numberline {1.16}{\ignorespaces \textbf {VISOR Annotations and Benchmarks.}Sparse annotations of the P06-03 scene, where flour becomes dough in the end.Each color represents a different object. In the bottom part the three proposed challenges are reported for the current scene. Namely: Semi-Supervised Video Object Semgentation(VOS), Hand Object Segmentation(HOS) and Where Did This Come From(WDTCF).}}{21}{figure.caption.37}%
\contentsline {figure}{\numberline {1.17}{\ignorespaces Example of Precision-recall curve.We can see how the bottom line model represents the worst a model can perform, e.g. predict every sample as it is coming from the same class,if the dataset is balanced. A better model would \textit {tend} to the upper-right corner, which instead represents the best possible model, a model that have maximum precision and recall.}}{25}{figure.caption.38}%
\addvspace {10\p@ }
\addvspace {10\p@ }
