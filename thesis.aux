\relax 
\providecommand{\transparent@use}[1]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand*\new@tpo@label[2]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{none/global//global/global}
\providecommand \oddpage@label [2]{}
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\@newglossary{abbreviations}{glg-abr}{gls-abr}{glo-abr}
\providecommand\@glsxtr@savepreloctag[2]{}
\providecommand\@glsorder[1]{}
\providecommand\@istfilename[1]{}
\@istfilename{thesis.ist}
\@glsorder{word}
\babel@aux{italian}{}
\babel@aux{italian}{}
\babel@aux{italian}{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {chapter}{List of Tables}{v}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Figures}{vi}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Acronyms}{ix}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {part}{I\hspace  {1em}Our Contribution}{2}{part.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Methodology}{3}{chapter.1.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Goals}{3}{section.1.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Second Goal}{3}{section*.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Reconstruction of a pizza preparation video. The top and bottom frames give us a glance of the action performed during the video while the central pointcloud highlighht the problems of SfM in dynamic environments like the superimposition of the same object on itself or the reconstruction of objects that are not always present in the scene, e.g. the two pizzas.}}{4}{figure.caption.5}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:pizza}{{1.1}{4}{Reconstruction of a pizza preparation video. The top and bottom frames give us a glance of the action performed during the video while the central pointcloud highlighht the problems of SfM in dynamic environments like the superimposition of the same object on itself or the reconstruction of objects that are not always present in the scene, e.g. the two pizzas}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Pipelines}{4}{section.1.1.2}\protected@file@percent }
\abx@aux@cite{0}{neuraldiff}
\abx@aux@segm{0}{0}{neuraldiff}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces \textbf  {Basic Pipeline.} In the Basic Pipeline a video(represented by the image of a person cooking) is subsampled through EF-Sampling, reconstructed via COLMAP, re-sampled on the reconstructed frames and then fed to NeuralDiff. At this stage the frames are decomposed in actor,foreground and background(as can be seen in the frames reported below NeuralDiff). The Clean reconstruction is obtained by running another COLMAP step on the extracted background frames.}}{5}{figure.caption.8}\protected@file@percent }
\newlabel{fig:dumb}{{1.2}{5}{\textbf {Basic Pipeline.} In the Basic Pipeline a video(represented by the image of a person cooking) is subsampled through EF-Sampling, reconstructed via COLMAP, re-sampled on the reconstructed frames and then fed to NeuralDiff. At this stage the frames are decomposed in actor,foreground and background(as can be seen in the frames reported below NeuralDiff). The Clean reconstruction is obtained by running another COLMAP step on the extracted background frames}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {paragraph}{Colmap Pipeline}{5}{section*.7}\protected@file@percent }
\abx@aux@backref{1}{neuraldiff}{0}{5}{5}
\@writefile{toc}{\contentsline {paragraph}{Monocular Pipeline}{5}{section*.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces \textbf  {Monocular Pipeline.} The Monocular pipeline share the first part with the Basic Pipeline. A video is subsampled,reconstructed via COLMAP, subsampled again and fed to Neuraldiff. The difference is that here the dynamic layers are projected in 3D and points closer than a distance th are segmented as dynamic.}}{6}{figure.caption.10}\protected@file@percent }
\newlabel{fig:monoPipe}{{1.3}{6}{\textbf {Monocular Pipeline.} The Monocular pipeline share the first part with the Basic Pipeline. A video is subsampled,reconstructed via COLMAP, subsampled again and fed to Neuraldiff. The difference is that here the dynamic layers are projected in 3D and points closer than a distance th are segmented as dynamic}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {paragraph}{NeuralDiff Pipeline}{6}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{NeuralCleaner}{6}{section*.13}\protected@file@percent }
\abx@aux@cite{0}{epic_fields}
\abx@aux@segm{0}{0}{epic_fields}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces \textbf  {NeuralDiff Pipeline.}In this pipeline we obtain the three motion layers as in the other methods but actually the segmentation is performed querying the static neural renderer with the positions of the points belonging to the COLMAP reconstruction. Each point is segmented as dynamic if its density is less than a predefined value.}}{7}{figure.caption.12}\protected@file@percent }
\newlabel{fig:ndiffPipe}{{1.4}{7}{\textbf {NeuralDiff Pipeline.}In this pipeline we obtain the three motion layers as in the other methods but actually the segmentation is performed querying the static neural renderer with the positions of the points belonging to the COLMAP reconstruction. Each point is segmented as dynamic if its density is less than a predefined value}{figure.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Filtering }{7}{section.1.1.3}\protected@file@percent }
\newlabel{sec:sampl}{{1.3}{7}{Filtering}{section.1.1.3}{}}
\abx@aux@backref{2}{epic_fields}{0}{7}{7}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Sampling Steps in our pipelines. The initial video is subsampled by EF-Sampling and the resulting frames are fed to COLMAP. Onve COLMAP reconstructed the scene these frames are again subsampled via Intelligent Sampling and fed to NeuralDiff.}}{8}{figure.caption.14}\protected@file@percent }
\newlabel{fig:samplPipe}{{1.5}{8}{Sampling Steps in our pipelines. The initial video is subsampled by EF-Sampling and the resulting frames are fed to COLMAP. Onve COLMAP reconstructed the scene these frames are again subsampled via Intelligent Sampling and fed to NeuralDiff}{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Example of overlapping frames(X and Y). The left and central examples present the same level of overlap even though the image frames are closer together in the central example, because the number of features shared are the same. The right examples instead present a higher level of overlapping due to the bigger number of features.}}{9}{figure.caption.15}\protected@file@percent }
\newlabel{fig:overlap}{{1.6}{9}{Example of overlapping frames(X and Y). The left and central examples present the same level of overlap even though the image frames are closer together in the central example, because the number of features shared are the same. The right examples instead present a higher level of overlapping due to the bigger number of features}{figure.caption.15}{}}
\abx@aux@cite{0}{neuraldiff}
\abx@aux@segm{0}{0}{neuraldiff}
\abx@aux@cite{0}{visor}
\abx@aux@segm{0}{0}{visor}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Experiments}{10}{chapter.1.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Data selection}{10}{section.1.2.1}\protected@file@percent }
\abx@aux@backref{3}{neuraldiff}{0}{10}{10}
\abx@aux@backref{4}{visor}{0}{10}{10}
\abx@aux@cite{0}{epic_fields}
\abx@aux@segm{0}{0}{epic_fields}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Total Frames for each scene}}{11}{table.caption.16}\protected@file@percent }
\newlabel{tab:Frames}{{2.1}{11}{Total Frames for each scene}{table.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Example of VISOR active annotations, on the left 'wash a knife' include the static sink as active; on the right 'pour spice' static gas stove is active}}{11}{figure.caption.17}\protected@file@percent }
\newlabel{fig:vis_exp}{{2.1}{11}{Example of VISOR active annotations, on the left 'wash a knife' include the static sink as active; on the right 'pour spice' static gas stove is active}{figure.caption.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}COLMAP Reconstruction}{11}{section.1.2.2}\protected@file@percent }
\abx@aux@backref{5}{epic_fields}{0}{11}{11}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Recostruction of scene P01\_01 with details}}{12}{table.caption.18}\protected@file@percent }
\newlabel{tab:col_P01_01}{{2.2}{12}{Recostruction of scene P01\_01 with details}{table.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Varying COLMAP pcd reconstruction changing number of samples and resolution. Each row is the same reconstruction viewed from different viewpoints.From top to bottom the number of frames increase, while in the first two rows the same split is compared using different resolutions.}}{13}{figure.caption.19}\protected@file@percent }
\newlabel{fig:colmap_P01}{{2.2}{13}{Varying COLMAP pcd reconstruction changing number of samples and resolution. Each row is the same reconstruction viewed from different viewpoints.From top to bottom the number of frames increase, while in the first two rows the same split is compared using different resolutions}{figure.caption.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Monocular Pipeline}{13}{section.1.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Frame and its projection in the 3D space.}}{14}{figure.caption.20}\protected@file@percent }
\newlabel{fig:Monoc}{{2.3}{14}{Frame and its projection in the 3D space}{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Scene cleaned from dynamic points. (Dovrei rifarla...)}}{14}{figure.caption.21}\protected@file@percent }
\newlabel{fig:glob}{{2.4}{14}{Scene cleaned from dynamic points. (Dovrei rifarla...)}{figure.caption.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}NeuralDiff Pipeline}{15}{section.1.2.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2.3}{\ignorespaces Results of NeuralDiff pipeline trained on various frame splits.}}{15}{table.caption.22}\protected@file@percent }
\newlabel{tab:EpicInt114}{{2.3}{15}{Results of NeuralDiff pipeline trained on various frame splits}{table.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Visualization of the output of the different models trained on differen splits.}}{17}{figure.caption.23}\protected@file@percent }
\newlabel{fig:comp}{{2.5}{17}{Visualization of the output of the different models trained on differen splits}{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Qualitative results for the static reconstruction of P01-01 scene at 217 frames. In red is highlighted a dynamic plate, while in green a dynamic pan.}}{18}{figure.caption.24}\protected@file@percent }
\newlabel{fig:statP01_01}{{2.6}{18}{Qualitative results for the static reconstruction of P01-01 scene at 217 frames. In red is highlighted a dynamic plate, while in green a dynamic pan}{figure.caption.24}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.4}{\ignorespaces Results all scenes Epic 114}}{19}{table.caption.26}\protected@file@percent }
\newlabel{tab:Epic_res}{{2.4}{19}{Results all scenes Epic 114}{table.caption.26}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.5}{\ignorespaces Metrics for comparing the profile of the histograms. In particular higher values of Cosine similarity and Correlation indicates similarity; while the value of the two divergences represents the distance between the two distributions.}}{20}{table.caption.31}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Comparative of the qualitative results for different samplings of the P01-01 scene.}}{21}{figure.caption.25}\protected@file@percent }
\newlabel{fig:statP01_02}{{2.7}{21}{Comparative of the qualitative results for different samplings of the P01-01 scene}{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Experiments performed on 228x128 frames for each scene}}{22}{figure.caption.27}\protected@file@percent }
\newlabel{fig:Epic228}{{2.8}{22}{Experiments performed on 228x128 frames for each scene}{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Visualization of the sampling for the three different methods: Intelligent, Uniform and AU using 217 frames in total.}}{23}{figure.caption.28}\protected@file@percent }
\newlabel{fig:samplFreq}{{2.9}{23}{Visualization of the sampling for the three different methods: Intelligent, Uniform and AU using 217 frames in total}{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Comparison of frequencies for the Intelligent and Uniform sampling with the Object Count for the P01-01 scene changing the total number of sampled frames.}}{24}{figure.caption.29}\protected@file@percent }
\newlabel{fig:samplFreq}{{2.10}{24}{Comparison of frequencies for the Intelligent and Uniform sampling with the Object Count for the P01-01 scene changing the total number of sampled frames}{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Comparison of frequencies for the Intelligent and Uniform sampling with the Object Count for each scene at a fixed split \~1000 frames.}}{25}{figure.caption.30}\protected@file@percent }
\newlabel{fig:samplFreq}{{2.11}{25}{Comparison of frequencies for the Intelligent and Uniform sampling with the Object Count for each scene at a fixed split \~1000 frames}{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Results for architecture with foreground+actor= fused}}{26}{figure.caption.32}\protected@file@percent }
\newlabel{fig:NeuralCleaner}{{2.12}{26}{Results for architecture with foreground+actor= fused}{figure.caption.32}{}}
\@writefile{toc}{\contentsline {part}{II\hspace  {1em}Conclusions}{27}{part.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Cnclusions}{28}{chapter.2.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Galileo}{29}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec:appendix_galileo}{{A}{29}{Conclusions}{appendix.A}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Math Notation}{30}{appendix.B}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:MathNotation}{{B}{30}{Conclusions}{appendix.B}{}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{31}{appendix.B}\protected@file@percent }
\abx@aux@read@bbl@mdfivesum{8DF43145C2502C13E515493DCF29FDDE}
\abx@aux@read@bblrerun
\abx@aux@defaultrefcontext{0}{epic_fields}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{neuraldiff}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{visor}{none/global//global/global}
\gdef\svg@ink@ver@settings{{\m@ne }{inkscape}{\m@ne }}
\gdef \@abspage@last{42}
