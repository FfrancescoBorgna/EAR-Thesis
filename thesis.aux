\relax 
\providecommand{\transparent@use}[1]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand*\new@tpo@label[2]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{none/global//global/global}
\providecommand \oddpage@label [2]{}
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\@newglossary{abbreviations}{glg-abr}{gls-abr}{glo-abr}
\providecommand\@glsxtr@savepreloctag[2]{}
\providecommand\@glsorder[1]{}
\providecommand\@istfilename[1]{}
\@istfilename{thesis.ist}
\@glsorder{word}
\babel@aux{italian}{}
\babel@aux{italian}{}
\babel@aux{italian}{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {chapter}{List of Tables}{vii}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Figures}{viii}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Acronyms}{xii}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {part}{I\hspace  {1em}Related Works}{1}{part.1}\protected@file@percent }
\newlabel{sec:Related}{{I}{2}{Related Works}{part.1}{}}
\abx@aux@cite{0}{EPICKITCHENS}
\abx@aux@segm{0}{0}{EPICKITCHENS}
\abx@aux@cite{0}{residualImage}
\abx@aux@segm{0}{0}{residualImage}
\abx@aux@cite{0}{fasterRCNN}
\abx@aux@segm{0}{0}{fasterRCNN}
\abx@aux@cite{0}{captioning}
\abx@aux@segm{0}{0}{captioning}
\abx@aux@cite{0}{vqa}
\abx@aux@segm{0}{0}{vqa}
\abx@aux@cite{0}{pascalImage}
\abx@aux@segm{0}{0}{pascalImage}
\abx@aux@cite{0}{imagenet}
\abx@aux@segm{0}{0}{imagenet}
\abx@aux@cite{0}{COCO}
\abx@aux@segm{0}{0}{COCO}
\abx@aux@cite{0}{ADE20K}
\abx@aux@segm{0}{0}{ADE20K}
\abx@aux@cite{0}{somethingSomething}
\abx@aux@segm{0}{0}{somethingSomething}
\abx@aux@cite{0}{yt}
\abx@aux@segm{0}{0}{yt}
\abx@aux@cite{0}{movieBench}
\abx@aux@segm{0}{0}{movieBench}
\abx@aux@cite{0}{movieQA}
\abx@aux@segm{0}{0}{movieQA}
\abx@aux@cite{0}{vlogs}
\abx@aux@segm{0}{0}{vlogs}
\abx@aux@cite{0}{movieQA}
\abx@aux@segm{0}{0}{movieQA}
\abx@aux@cite{0}{charades}
\abx@aux@segm{0}{0}{charades}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Datasets}{3}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}EPIC-Kitchens}{3}{section.1.1}\protected@file@percent }
\newlabel{sec:EK}{{1.1}{3}{EPIC-Kitchens}{section.1.1}{}}
\abx@aux@backref{3}{EPICKITCHENS}{0}{3}{3}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Introduction/motivation}{3}{subsection.1.1.1}\protected@file@percent }
\abx@aux@backref{4}{residualImage}{0}{3}{3}
\abx@aux@backref{5}{fasterRCNN}{0}{3}{3}
\abx@aux@backref{6}{captioning}{0}{3}{3}
\abx@aux@backref{7}{vqa}{0}{3}{3}
\abx@aux@backref{8}{pascalImage}{0}{3}{3}
\abx@aux@backref{9}{imagenet}{0}{3}{3}
\abx@aux@backref{10}{COCO}{0}{3}{3}
\abx@aux@backref{11}{ADE20K}{0}{3}{3}
\abx@aux@backref{12}{somethingSomething}{0}{3}{3}
\abx@aux@backref{13}{yt}{0}{3}{3}
\abx@aux@backref{14}{movieBench}{0}{3}{3}
\abx@aux@backref{15}{movieQA}{0}{3}{3}
\abx@aux@backref{16}{vlogs}{0}{3}{3}
\abx@aux@backref{17}{movieQA}{0}{3}{3}
\abx@aux@backref{18}{charades}{0}{3}{3}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Comparative overview of relevant datasets(action classes with > 50 samples)}}{4}{table.caption.4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:epic_comparison}{{1.1}{4}{Comparative overview of relevant datasets(action classes with > 50 samples)}{table.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Data Collection}{4}{subsection.1.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces \textbf  {Top} (left to right): time of day of the recording, pie chart of high-level goals, histogram of sequence durations and dataset logo; \textbf  {Bottom}:Wordles of narrations in native languages(English, Italian, Spanish, Greek and Chinese).}}{5}{figure.caption.5}\protected@file@percent }
\newlabel{fig:epic_stat}{{1.1}{5}{\textbf {Top} (left to right): time of day of the recording, pie chart of high-level goals, histogram of sequence durations and dataset logo; \textbf {Bottom}:Wordles of narrations in native languages(English, Italian, Spanish, Greek and Chinese)}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}Data Annotation pipeline}{5}{subsection.1.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Narration Guidelines given to each participant to be followed after the completion of a recording.}}{5}{figure.caption.6}\protected@file@percent }
\newlabel{fig:epic_guidelines}{{1.2}{5}{Narration Guidelines given to each participant to be followed after the completion of a recording}{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Extracts from 6 transcription files in .sbv format}}{6}{figure.caption.7}\protected@file@percent }
\newlabel{fig:epic_trans}{{1.3}{6}{Extracts from 6 transcription files in .sbv format}{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Example of annotated action segments for 2 consecutive actions}}{7}{figure.caption.8}\protected@file@percent }
\newlabel{fig:epic_anno}{{1.4}{7}{Example of annotated action segments for 2 consecutive actions}{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Sample Verb and Noun Classes}}{7}{figure.caption.9}\protected@file@percent }
\newlabel{fig:epic_table}{{1.5}{7}{Sample Verb and Noun Classes}{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces \textbf  {From Top:} Frequency of verb classes in action segments; Frequency of noun clusters in action segments, by category; Frequency of noun clusters in bounding box annotations, by category; Mean and standard deviation of bounding box, by category}}{8}{figure.caption.10}\protected@file@percent }
\newlabel{fig:epic_freq}{{1.6}{8}{\textbf {From Top:} Frequency of verb classes in action segments; Frequency of noun clusters in action segments, by category; Frequency of noun clusters in bounding box annotations, by category; Mean and standard deviation of bounding box, by category}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.4}Benchmarks and Baseline Results}{8}{subsection.1.1.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces Sample consecutive action segments with keyframe object annotations}}{9}{figure.caption.11}\protected@file@percent }
\newlabel{fig:epic_bb}{{1.7}{9}{Sample consecutive action segments with keyframe object annotations}{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{Action Recognition Challenge}{9}{section*.12}\protected@file@percent }
\newlabel{sec:ep_AR_chall}{{1.1.4}{9}{Action Recognition Challenge}{section*.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{Action Anticipation Challenge}{9}{section*.14}\protected@file@percent }
\newlabel{sec:ep_AA_chall}{{1.1.4}{9}{Action Anticipation Challenge}{section*.14}{}}
\abx@aux@cite{0}{EK100}
\abx@aux@segm{0}{0}{EK100}
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Sample qualitative results from the challenge's baseline of the Action Recognition Task}}{10}{figure.caption.13}\protected@file@percent }
\newlabel{fig:epic_ar_chall}{{1.8}{10}{Sample qualitative results from the challenge's baseline of the Action Recognition Task}{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces Sample qualitative results from the challenge's baseline of the Action Anticipation Task}}{10}{figure.caption.15}\protected@file@percent }
\newlabel{fig:epic_aa_chall}{{1.9}{10}{Sample qualitative results from the challenge's baseline of the Action Anticipation Task}{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{Object Detection Challenge}{10}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.5}Dataset Release}{10}{subsection.1.1.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces Sample qualitative results from the challenge's baseline of the Object Detection Task}}{11}{figure.caption.17}\protected@file@percent }
\newlabel{fig:epic_od_chall}{{1.10}{11}{Sample qualitative results from the challenge's baseline of the Object Detection Task}{figure.caption.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}EPIC-Kitchens 100}{11}{section.1.2}\protected@file@percent }
\newlabel{sec:EK100}{{1.2}{11}{EPIC-Kitchens 100}{section.1.2}{}}
\abx@aux@backref{19}{EK100}{0}{11}{11}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Motivation}{11}{subsection.1.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Data Collection}{12}{subsection.1.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Annotation}{12}{subsection.1.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Narrator}{12}{section*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Transcriber}{12}{section*.20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Parser}{12}{section*.21}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.11}{\ignorespaces Annotation pipeline: \textbf  {a} narrator, \textbf  {b} transcriber \textbf  {c} temporal segment annotator and \textbf  {d} dependency parser. Red arrows show AMT crowdsourcing of annotations.}}{13}{figure.caption.18}\protected@file@percent }
\newlabel{fig:e100_ann}{{1.11}{13}{Annotation pipeline: \textbf {a} narrator, \textbf {b} transcriber \textbf {c} temporal segment annotator and \textbf {d} dependency parser. Red arrows show AMT crowdsourcing of annotations}{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsubsection}{Temporal Annotator}{13}{section*.22}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.4}Quality Improvements}{13}{subsection.1.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.12}{\ignorespaces Comparing non-stop narrations (blue) to 'pause-and-talk' narrations (red). Right: timestsamps (dots) and segments (bars) for two sample sequences. "pause-and-talk" captures all actions including short ones. Black frames depict missed actions.}}{14}{figure.caption.23}\protected@file@percent }
\newlabel{fig:ep100_comp}{{1.12}{14}{Comparing non-stop narrations (blue) to 'pause-and-talk' narrations (red). Right: timestsamps (dots) and segments (bars) for two sample sequences. "pause-and-talk" captures all actions including short ones. Black frames depict missed actions}{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.5}Challenges and Baselines}{14}{subsection.1.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}EPIC-Fields:\textcolor {red}{Lo metto?Anche se non l'abbiamo usato?}}{14}{section.1.3}\protected@file@percent }
\abx@aux@cite{0}{visor35}
\abx@aux@segm{0}{0}{visor35}
\abx@aux@cite{0}{visor5}
\abx@aux@segm{0}{0}{visor5}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Data}{15}{subsection.1.3.1}\protected@file@percent }
\abx@aux@backref{20}{visor35}{0}{15}{15}
\abx@aux@backref{21}{visor5}{0}{15}{15}
\@writefile{toc}{\contentsline {subsubsection}{Motivation.}{15}{section*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Collection}{15}{section*.25}\protected@file@percent }
\abx@aux@cite{0}{nerf}
\abx@aux@segm{0}{0}{nerf}
\@writefile{toc}{\contentsline {subsubsection}{Filtering}{16}{section*.26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Sparse reconstruction}{16}{section*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Dense reconstruction, automated verification, and restart}{16}{section*.28}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Benchmarks, Experiments and Results}{16}{subsection.1.3.2}\protected@file@percent }
\abx@aux@cite{0}{neuraldiff}
\abx@aux@segm{0}{0}{neuraldiff}
\abx@aux@cite{0}{nerfw}
\abx@aux@segm{0}{0}{nerfw}
\abx@aux@cite{0}{Tnerf}
\abx@aux@segm{0}{0}{Tnerf}
\abx@aux@cite{0}{nerfw}
\abx@aux@segm{0}{0}{nerfw}
\abx@aux@cite{0}{Tnerf}
\abx@aux@segm{0}{0}{Tnerf}
\abx@aux@cite{0}{neuraldiff}
\abx@aux@segm{0}{0}{neuraldiff}
\abx@aux@cite{0}{neuraldiff}
\abx@aux@segm{0}{0}{neuraldiff}
\@writefile{toc}{\contentsline {subsubsection}{New-View Synthesis(NVS)}{17}{section*.29}\protected@file@percent }
\abx@aux@backref{22}{nerf}{0}{17}{17}
\abx@aux@backref{23}{neuraldiff}{0}{17}{17}
\abx@aux@backref{24}{nerfw}{0}{17}{17}
\abx@aux@backref{25}{Tnerf}{0}{17}{17}
\abx@aux@cite{0}{MG}
\abx@aux@segm{0}{0}{MG}
\abx@aux@cite{0}{MG}
\abx@aux@segm{0}{0}{MG}
\abx@aux@cite{0}{nerfw}
\abx@aux@segm{0}{0}{nerfw}
\abx@aux@cite{0}{Tnerf}
\abx@aux@segm{0}{0}{Tnerf}
\abx@aux@cite{0}{neuraldiff}
\abx@aux@segm{0}{0}{neuraldiff}
\abx@aux@backref{26}{nerfw}{0}{18}{18}
\abx@aux@backref{27}{Tnerf}{0}{18}{18}
\abx@aux@backref{28}{neuraldiff}{0}{18}{18}
\@writefile{lot}{\contentsline {table}{\numberline {1.2}{\ignorespaces \textbf  {Dynamic New View Synthesis.}Comparison of different neural rendering methods on varying difficult frames. The values reported corresponds to PSNR considering all pixels in each test frame.}}{18}{table.caption.30}\protected@file@percent }
\newlabel{tab:NVS_comp}{{1.2}{18}{\textbf {Dynamic New View Synthesis.}Comparison of different neural rendering methods on varying difficult frames. The values reported corresponds to PSNR considering all pixels in each test frame}{table.caption.30}{}}
\@writefile{toc}{\contentsline {subsubsection}{Unsupervised Dynamic Object Segmentation(UDOS)}{18}{section*.32}\protected@file@percent }
\abx@aux@backref{29}{neuraldiff}{0}{18}{18}
\abx@aux@backref{30}{MG}{0}{18}{18}
\@writefile{lof}{\contentsline {figure}{\numberline {1.13}{\ignorespaces \textbf  {Dynamic New View Synthesis}. I report an example of the output for the three different methods used: NeRF-W, T-NeRF+ and NeuralDiff. We can see how the initial labelling of difficulty for frames was actually accurate as the reconstructions struggle with Hard frames.}}{19}{figure.caption.31}\protected@file@percent }
\newlabel{fig:NVS}{{1.13}{19}{\textbf {Dynamic New View Synthesis}. I report an example of the output for the three different methods used: NeRF-W, T-NeRF+ and NeuralDiff. We can see how the initial labelling of difficulty for frames was actually accurate as the reconstructions struggle with Hard frames}{figure.caption.31}{}}
\@writefile{toc}{\contentsline {subsubsection}{Semi-Supervised Video Object Segmentation(VOS)}{19}{section*.35}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.14}{\ignorespaces \textbf  {UDOS.} Here is reported the comparison of the different methods' output. The 2D based perform very good on dynamic objects, while 3D methods struggle a bit but can detect even semi-static objects.}}{20}{figure.caption.33}\protected@file@percent }
\newlabel{fig:UDOS}{{1.14}{20}{\textbf {UDOS.} Here is reported the comparison of the different methods' output. The 2D based perform very good on dynamic objects, while 3D methods struggle a bit but can detect even semi-static objects}{figure.caption.33}{}}
\abx@aux@backref{31}{MG}{0}{20}{20}
\abx@aux@backref{32}{nerfw}{0}{20}{20}
\abx@aux@backref{33}{Tnerf}{0}{20}{20}
\abx@aux@backref{34}{neuraldiff}{0}{20}{20}
\@writefile{lot}{\contentsline {table}{\numberline {1.3}{\ignorespaces \textbf  {UDOS.} Here I reported the author results for UDOS. The values visible corresponds to the mAP on segmenting semi-static(SS) and dynamic(Dyn) components of the scene.}}{20}{table.caption.34}\protected@file@percent }
\newlabel{tab:UDOS}{{1.3}{20}{\textbf {UDOS.} Here I reported the author results for UDOS. The values visible corresponds to the mAP on segmenting semi-static(SS) and dynamic(Dyn) components of the scene}{table.caption.34}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}VISOR \textcolor {red}{Lo metto?non usato}}{20}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.5}((Ego4D))}{20}{section.1.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.15}{\ignorespaces \textbf  {VOS.} Here is reported the comparison of the two different methods. The 3D method is clearly beter having as output something really close to the groundtruth. The 2D method instead is performing poorly.}}{21}{figure.caption.36}\protected@file@percent }
\newlabel{fig:VOS}{{1.15}{21}{\textbf {VOS.} Here is reported the comparison of the two different methods. The 3D method is clearly beter having as output something really close to the groundtruth. The 2D method instead is performing poorly}{figure.caption.36}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Neural Rendering}{22}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec:Neural}{{2}{22}{((Ego4D))}{chapter.2}{}}
\abx@aux@cite{0}{examplewebsite}
\abx@aux@segm{0}{0}{examplewebsite}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Photogrammetry}{23}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\abx@aux@backref{35}{examplewebsite}{0}{23}{23}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces \textbf  {Pinhole Camera.} A world's object is captured by the camera making light passing through the pinhole and is then projected on the focal plane upside-down.}}{23}{figure.caption.37}\protected@file@percent }
\newlabel{fig:pinhole}{{3.1}{23}{\textbf {Pinhole Camera.} A world's object is captured by the camera making light passing through the pinhole and is then projected on the focal plane upside-down}{figure.caption.37}{}}
\abx@aux@cite{0}{sfm_matlab}
\abx@aux@segm{0}{0}{sfm_matlab}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Structure from Motion: SfM}{24}{section.3.1}\protected@file@percent }
\abx@aux@backref{36}{sfm_matlab}{0}{24}{24}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces \textbf  {Reference systems.} An example of the different refernce systems involved in a photogrammetry problem.In red is reported the world system while in black the camera one. The yellow plane corresponds to the camera focal plane.}}{25}{figure.caption.38}\protected@file@percent }
\newlabel{fig:reference_systems}{{3.2}{25}{\textbf {Reference systems.} An example of the different refernce systems involved in a photogrammetry problem.In red is reported the world system while in black the camera one. The yellow plane corresponds to the camera focal plane}{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces \textbf  {Basic SfM Scenario.} Two cameras capturing the same object from different viewpoints.}}{25}{figure.caption.39}\protected@file@percent }
\newlabel{fig:sfm_basic}{{3.3}{25}{\textbf {Basic SfM Scenario.} Two cameras capturing the same object from different viewpoints}{figure.caption.39}{}}
\abx@aux@cite{0}{open_cv}
\abx@aux@segm{0}{0}{open_cv}
\abx@aux@cite{0}{open_cv}
\abx@aux@segm{0}{0}{open_cv}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Feature Detection and Matching }{26}{subsection.3.1.1}\protected@file@percent }
\abx@aux@cite{0}{open_cv}
\abx@aux@segm{0}{0}{open_cv}
\abx@aux@cite{0}{Lowe04_SIFT}
\abx@aux@segm{0}{0}{Lowe04_SIFT}
\abx@aux@cite{0}{BAY_SURF}
\abx@aux@segm{0}{0}{BAY_SURF}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces \textbf  {Feature Detection Example}~\blx@tocontentsinit {0}\cite {open_cv}. The easier patches to match to the background are the ones with sharp corners.}}{27}{figure.caption.40}\protected@file@percent }
\abx@aux@backref{38}{open_cv}{0}{27}{27}
\newlabel{fig:sfm_opencv}{{3.4}{27}{\textbf {Feature Detection Example}~\cite {open_cv}. The easier patches to match to the background are the ones with sharp corners}{figure.caption.40}{}}
\abx@aux@backref{39}{open_cv}{0}{27}{27}
\abx@aux@backref{40}{Lowe04_SIFT}{0}{27}{27}
\abx@aux@backref{41}{BAY_SURF}{0}{27}{27}
\abx@aux@cite{0}{Brief}
\abx@aux@segm{0}{0}{Brief}
\abx@aux@cite{0}{ORB}
\abx@aux@segm{0}{0}{ORB}
\abx@aux@backref{42}{Brief}{0}{28}{28}
\abx@aux@backref{43}{ORB}{0}{28}{28}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces \textbf  {SIFT features position.}Example of interest points, we can see that most of them are placed around corners or edges.}}{28}{figure.caption.41}\protected@file@percent }
\newlabel{fig:sift}{{3.5}{28}{\textbf {SIFT features position.}Example of interest points, we can see that most of them are placed around corners or edges}{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces \textbf  {Features correspondence} computed using BruteForce Matcher.}}{29}{figure.caption.42}\protected@file@percent }
\newlabel{fig:politoCorresponance}{{3.6}{29}{\textbf {Features correspondence} computed using BruteForce Matcher}{figure.caption.42}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Estimating Fundamental and Essential Matrices}{29}{subsection.3.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces \textbf  {Point correspondence geometry.} In particular are reported: the \textit  {epipoles} e, e';the \textit  {epipolar plane}, which is any plane containing the line that connects the two camera centers, also known as \textit  {baseline}; the \textit  {Epipolar line} which is the intersection of any epipolar plane with the image plane.}}{30}{figure.caption.43}\protected@file@percent }
\newlabel{fig:epipolar}{{3.7}{30}{\textbf {Point correspondence geometry.} In particular are reported: the \textit {epipoles} e, e';the \textit {epipolar plane}, which is any plane containing the line that connects the two camera centers, also known as \textit {baseline}; the \textit {Epipolar line} which is the intersection of any epipolar plane with the image plane}{figure.caption.43}{}}
\newlabel{eq:E1}{{3.1}{30}{Estimating Fundamental and Essential Matrices}{equation.3.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces A point X viewed from two cameras with $x_l$ being the distance of X from $C_l$ and $x_r$ being the distance of X from $C_r$. $p_r$ and $p_l$ are instead the projection of X on the respective camera's focal plane.}}{31}{figure.caption.44}\protected@file@percent }
\newlabel{fig:EstimateMatrices}{{3.8}{31}{A point X viewed from two cameras with $x_l$ being the distance of X from $C_l$ and $x_r$ being the distance of X from $C_r$. $p_r$ and $p_l$ are instead the projection of X on the respective camera's focal plane}{figure.caption.44}{}}
\newlabel{eq:EssentialMatrix}{{3.4}{31}{Estimating Fundamental and Essential Matrices}{equation.3.1.4}{}}
\newlabel{eq:Fund}{{3.7}{31}{Estimating Fundamental and Essential Matrices}{equation.3.1.7}{}}
\abx@aux@cite{0}{bundle}
\abx@aux@segm{0}{0}{bundle}
\abx@aux@cite{0}{colmap}
\abx@aux@segm{0}{0}{colmap}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Estimating Camera Pose from Essential Matrix}{32}{subsection.3.1.3}\protected@file@percent }
\newlabel{eq:t}{{3.9}{32}{Estimating Camera Pose from Essential Matrix}{equation.3.1.9}{}}
\newlabel{eq:tR}{{3.10}{32}{Estimating Camera Pose from Essential Matrix}{equation.3.1.10}{}}
\newlabel{eq:W}{{3.11}{32}{Estimating Camera Pose from Essential Matrix}{equation.3.1.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}Multi-view Structure from Motion}{32}{subsection.3.1.4}\protected@file@percent }
\abx@aux@backref{44}{bundle}{0}{32}{32}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.5}COLMAP}{32}{subsection.3.1.5}\protected@file@percent }
\newlabel{sec:col}{{3.1.5}{32}{COLMAP}{subsection.3.1.5}{}}
\abx@aux@cite{0}{schoenberger2016sfm}
\abx@aux@segm{0}{0}{schoenberger2016sfm}
\abx@aux@cite{0}{schoenberger2016mvs}
\abx@aux@segm{0}{0}{schoenberger2016mvs}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces \textbf  {Multiple View Scenario.} In multiple view scenario multiple cameras are present, each one recording the scene from a different point of view.}}{33}{figure.caption.45}\protected@file@percent }
\newlabel{fig:multiview}{{3.9}{33}{\textbf {Multiple View Scenario.} In multiple view scenario multiple cameras are present, each one recording the scene from a different point of view}{figure.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces \textbf  {Building Rome in one day.} Result of Rome with 21K registered out of 75K images.}}{33}{figure.caption.46}\protected@file@percent }
\newlabel{fig:colmap_image}{{3.10}{33}{\textbf {Building Rome in one day.} Result of Rome with 21K registered out of 75K images}{figure.caption.46}{}}
\abx@aux@backref{45}{colmap}{0}{33}{33}
\abx@aux@backref{46}{schoenberger2016sfm}{0}{34}{34}
\abx@aux@backref{47}{schoenberger2016mvs}{0}{34}{34}
\@writefile{toc}{\contentsline {subsubsection}{Usage}{34}{section*.47}\protected@file@percent }
\newlabel{lst:bash}{{3.1}{34}{Automatic COLMAP Reconstruction}{lstlisting.3.1}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.1}{\ignorespaces Automatic COLMAP Reconstruction}}{34}{lstlisting.3.1}\protected@file@percent }
\newlabel{lst:col}{{3.2}{34}{COLMAP Single Commands}{lstlisting.3.2}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.2}{\ignorespaces COLMAP Single Commands}}{34}{lstlisting.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.6}Monocular Depth Estimation}{35}{subsection.3.1.6}\protected@file@percent }
\abx@aux@cite{0}{Ranftl2021}
\abx@aux@segm{0}{0}{Ranftl2021}
\abx@aux@cite{0}{Ranftl2021}
\abx@aux@segm{0}{0}{Ranftl2021}
\abx@aux@cite{0}{Ranftl2022}
\abx@aux@segm{0}{0}{Ranftl2022}
\abx@aux@cite{0}{DIML}
\abx@aux@segm{0}{0}{DIML}
\abx@aux@cite{0}{megadepth}
\abx@aux@segm{0}{0}{megadepth}
\abx@aux@cite{0}{redweb}
\abx@aux@segm{0}{0}{redweb}
\abx@aux@cite{0}{wsvd}
\abx@aux@segm{0}{0}{wsvd}
\abx@aux@cite{0}{DIML}
\abx@aux@segm{0}{0}{DIML}
\abx@aux@cite{0}{diw}
\abx@aux@segm{0}{0}{diw}
\abx@aux@cite{0}{eth3d}
\abx@aux@segm{0}{0}{eth3d}
\abx@aux@cite{0}{sintel}
\abx@aux@segm{0}{0}{sintel}
\abx@aux@cite{0}{kitti}
\abx@aux@segm{0}{0}{kitti}
\abx@aux@cite{0}{nyudv2}
\abx@aux@segm{0}{0}{nyudv2}
\abx@aux@cite{0}{tum_rgbd}
\abx@aux@segm{0}{0}{tum_rgbd}
\abx@aux@cite{0}{Ranftl2022}
\abx@aux@segm{0}{0}{Ranftl2022}
\abx@aux@cite{0}{Ranftl2022}
\abx@aux@segm{0}{0}{Ranftl2022}
\abx@aux@backref{48}{Ranftl2021}{0}{36}{36}
\abx@aux@backref{49}{Ranftl2021}{0}{36}{36}
\abx@aux@backref{50}{Ranftl2022}{0}{36}{36}
\abx@aux@backref{51}{DIML}{0}{36}{36}
\abx@aux@backref{52}{megadepth}{0}{36}{36}
\abx@aux@backref{53}{redweb}{0}{36}{36}
\abx@aux@backref{54}{wsvd}{0}{36}{36}
\abx@aux@backref{55}{DIML}{0}{36}{36}
\abx@aux@backref{56}{diw}{0}{36}{36}
\abx@aux@backref{57}{eth3d}{0}{36}{36}
\abx@aux@backref{58}{sintel}{0}{36}{36}
\abx@aux@backref{59}{kitti}{0}{36}{36}
\abx@aux@backref{60}{nyudv2}{0}{36}{36}
\abx@aux@backref{61}{tum_rgbd}{0}{36}{36}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Monocular datasets}}{37}{figure.caption.48}\protected@file@percent }
\newlabel{fig:datasets_mono}{{3.11}{37}{Monocular datasets}{figure.caption.48}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces Top: input images. Middle: Inverse depth maps predicted by the presented approach. Bottom: corresponding point clouds rendered from a novel view-point.(Taken from~\blx@tocontentsinit {0}\cite {Ranftl2022})}}{37}{figure.caption.49}\protected@file@percent }
\abx@aux@backref{63}{Ranftl2022}{0}{37}{37}
\newlabel{fig:mono}{{3.12}{37}{Top: input images. Middle: Inverse depth maps predicted by the presented approach. Bottom: corresponding point clouds rendered from a novel view-point.(Taken from~\cite {Ranftl2022})}{figure.caption.49}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Your Table Caption Here}}{37}{table.caption.50}\protected@file@percent }
\newlabel{tab:mytable}{{3.1}{37}{Your Table Caption Here}{table.caption.50}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Your Table Caption Here}}{38}{table.caption.51}\protected@file@percent }
\newlabel{tab:mytable}{{3.2}{38}{Your Table Caption Here}{table.caption.51}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces Your Table Caption Here}}{39}{table.caption.52}\protected@file@percent }
\newlabel{tab:mytable}{{3.3}{39}{Your Table Caption Here}{table.caption.52}{}}
\@writefile{toc}{\contentsline {part}{II\hspace  {1em}Da Sistemare}{40}{part.2}\protected@file@percent }
\abx@aux@cite{0}{neuraldiff}
\abx@aux@segm{0}{0}{neuraldiff}
\newlabel{sec:Sistemare}{{II}{41}{Da Sistemare}{part.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Metrics}{41}{section.3.2}\protected@file@percent }
\newlabel{sec:Metrics}{{3.2}{41}{Metrics}{section.3.2}{}}
\abx@aux@backref{64}{neuraldiff}{0}{41}{41}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}PSNR:Peak signal-to-noise ratio}{41}{subsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}AP:Average Precision}{41}{subsection.3.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces Example of Precision-recall curve.We can see how the bottom line model represents the worst a model can perform, e.g. predict every sample as it is coming from the same class,if the dataset is balanced. A better model would \textit  {tend} to the upper-right corner, which instead represents the best possible model, a model that have maximum precision and recall.}}{42}{figure.caption.53}\protected@file@percent }
\newlabel{fig:auc}{{3.13}{42}{Example of Precision-recall curve.We can see how the bottom line model represents the worst a model can perform, e.g. predict every sample as it is coming from the same class,if the dataset is balanced. A better model would \textit {tend} to the upper-right corner, which instead represents the best possible model, a model that have maximum precision and recall}{figure.caption.53}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.4}{\ignorespaces Your Table Caption Here}}{43}{table.caption.54}\protected@file@percent }
\newlabel{tab:mytable}{{3.4}{43}{Your Table Caption Here}{table.caption.54}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.5}{\ignorespaces Your Table Caption Here}}{43}{table.caption.55}\protected@file@percent }
\newlabel{tab:mytable}{{3.5}{43}{Your Table Caption Here}{table.caption.55}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.6}{\ignorespaces Your Table Caption Here}}{44}{table.caption.56}\protected@file@percent }
\newlabel{tab:mytable}{{3.6}{44}{Your Table Caption Here}{table.caption.56}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Galileo}{45}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec:appendix_galileo}{{A}{45}{AP:Average Precision}{appendix.A}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Math Notation}{46}{appendix.B}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:MathNotation}{{B}{46}{AP:Average Precision}{appendix.B}{}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{47}{appendix.B}\protected@file@percent }
\abx@aux@read@bbl@mdfivesum{F889F9AFEF1B40CAA77DAF3DAAEE08AB}
\abx@aux@defaultrefcontext{0}{EPICKITCHENS}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{residualImage}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{fasterRCNN}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{captioning}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{vqa}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{pascalImage}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{imagenet}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{COCO}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{ADE20K}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{somethingSomething}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{yt}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{movieBench}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{movieQA}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{vlogs}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{charades}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{EK100}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{visor35}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{visor5}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{nerf}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{neuraldiff}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{nerfw}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Tnerf}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{MG}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{examplewebsite}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{sfm_matlab}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{open_cv}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Lowe04_SIFT}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{BAY_SURF}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Brief}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{ORB}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{bundle}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{colmap}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{schoenberger2016sfm}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{schoenberger2016mvs}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Ranftl2021}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Ranftl2022}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{DIML}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{megadepth}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{redweb}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{wsvd}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{diw}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{eth3d}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{sintel}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{kitti}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{nyudv2}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{tum_rgbd}{none/global//global/global}
\gdef\svg@ink@ver@settings{{\m@ne }{inkscape}{\m@ne }}
\gdef \@abspage@last{64}
