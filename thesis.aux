\relax 
\providecommand{\transparent@use}[1]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand*\new@tpo@label[2]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{none/global//global/global}
\providecommand \oddpage@label [2]{}
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\@newglossary{abbreviations}{glg-abr}{gls-abr}{glo-abr}
\providecommand\@glsxtr@savepreloctag[2]{}
\providecommand\@glsorder[1]{}
\providecommand\@istfilename[1]{}
\@istfilename{thesis.ist}
\@glsorder{word}
\babel@aux{italian}{}
\babel@aux{italian}{}
\babel@aux{italian}{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {chapter}{List of Tables}{vii}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Figures}{viii}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Acronyms}{xi}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {part}{I\hspace  {1em}Related Works}{1}{part.1}\protected@file@percent }
\newlabel{sec:Related}{{I}{2}{Related Works}{part.1}{}}
\abx@aux@cite{0}{EPICKITCHENS}
\abx@aux@segm{0}{0}{EPICKITCHENS}
\abx@aux@cite{0}{residualImage}
\abx@aux@segm{0}{0}{residualImage}
\abx@aux@cite{0}{fasterRCNN}
\abx@aux@segm{0}{0}{fasterRCNN}
\abx@aux@cite{0}{captioning}
\abx@aux@segm{0}{0}{captioning}
\abx@aux@cite{0}{vqa}
\abx@aux@segm{0}{0}{vqa}
\abx@aux@cite{0}{pascalImage}
\abx@aux@segm{0}{0}{pascalImage}
\abx@aux@cite{0}{imagenet}
\abx@aux@segm{0}{0}{imagenet}
\abx@aux@cite{0}{COCO}
\abx@aux@segm{0}{0}{COCO}
\abx@aux@cite{0}{ADE20K}
\abx@aux@segm{0}{0}{ADE20K}
\abx@aux@cite{0}{somethingSomething}
\abx@aux@segm{0}{0}{somethingSomething}
\abx@aux@cite{0}{yt}
\abx@aux@segm{0}{0}{yt}
\abx@aux@cite{0}{movieBench}
\abx@aux@segm{0}{0}{movieBench}
\abx@aux@cite{0}{movieQA}
\abx@aux@segm{0}{0}{movieQA}
\abx@aux@cite{0}{vlogs}
\abx@aux@segm{0}{0}{vlogs}
\abx@aux@cite{0}{movieQA}
\abx@aux@segm{0}{0}{movieQA}
\abx@aux@cite{0}{charades}
\abx@aux@segm{0}{0}{charades}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Datasets}{3}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}EPIC-Kitchens}{3}{section.1.1}\protected@file@percent }
\newlabel{sec:EK}{{1.1}{3}{EPIC-Kitchens}{section.1.1}{}}
\abx@aux@backref{3}{EPICKITCHENS}{0}{3}{3}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Introduction/motivation}{3}{subsection.1.1.1}\protected@file@percent }
\abx@aux@backref{4}{residualImage}{0}{3}{3}
\abx@aux@backref{5}{fasterRCNN}{0}{3}{3}
\abx@aux@backref{6}{captioning}{0}{3}{3}
\abx@aux@backref{7}{vqa}{0}{3}{3}
\abx@aux@backref{8}{pascalImage}{0}{3}{3}
\abx@aux@backref{9}{imagenet}{0}{3}{3}
\abx@aux@backref{10}{COCO}{0}{3}{3}
\abx@aux@backref{11}{ADE20K}{0}{3}{3}
\abx@aux@backref{12}{somethingSomething}{0}{3}{3}
\abx@aux@backref{13}{yt}{0}{3}{3}
\abx@aux@backref{14}{movieBench}{0}{3}{3}
\abx@aux@backref{15}{movieQA}{0}{3}{3}
\abx@aux@backref{16}{vlogs}{0}{3}{3}
\abx@aux@backref{17}{movieQA}{0}{3}{3}
\abx@aux@backref{18}{charades}{0}{3}{3}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Comparative overview of relevant datasets(action classes with > 50 samples)}}{4}{table.caption.4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:epic_comparison}{{1.1}{4}{Comparative overview of relevant datasets(action classes with > 50 samples)}{table.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Data Collection}{4}{subsection.1.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces \textbf  {Top} (left to right): time of day of the recording, pie chart of high-level goals, histogram of sequence durations and dataset logo; \textbf  {Bottom}:Wordles of narrations in native languages(English, Italian, Spanish, Greek and Chinese).}}{5}{figure.caption.5}\protected@file@percent }
\newlabel{fig:epic_stat}{{1.1}{5}{\textbf {Top} (left to right): time of day of the recording, pie chart of high-level goals, histogram of sequence durations and dataset logo; \textbf {Bottom}:Wordles of narrations in native languages(English, Italian, Spanish, Greek and Chinese)}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}Data Annotation pipeline}{5}{subsection.1.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Narration Guidelines given to each participant to be followed after the completion of a recording.}}{5}{figure.caption.6}\protected@file@percent }
\newlabel{fig:epic_guidelines}{{1.2}{5}{Narration Guidelines given to each participant to be followed after the completion of a recording}{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Extracts from 6 transcription files in .sbv format}}{6}{figure.caption.7}\protected@file@percent }
\newlabel{fig:epic_trans}{{1.3}{6}{Extracts from 6 transcription files in .sbv format}{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Example of annotated action segments for 2 consecutive actions}}{7}{figure.caption.8}\protected@file@percent }
\newlabel{fig:epic_anno}{{1.4}{7}{Example of annotated action segments for 2 consecutive actions}{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Sample Verb and Noun Classes}}{7}{figure.caption.9}\protected@file@percent }
\newlabel{fig:epic_table}{{1.5}{7}{Sample Verb and Noun Classes}{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces \textbf  {From Top:} Frequency of verb classes in action segments; Frequency of noun clusters in action segments, by category; Frequency of noun clusters in bounding box annotations, by category; Mean and standard deviation of bounding box, by category}}{8}{figure.caption.10}\protected@file@percent }
\newlabel{fig:epic_freq}{{1.6}{8}{\textbf {From Top:} Frequency of verb classes in action segments; Frequency of noun clusters in action segments, by category; Frequency of noun clusters in bounding box annotations, by category; Mean and standard deviation of bounding box, by category}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.4}Benchmarks and Baseline Results}{8}{subsection.1.1.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces Sample consecutive action segments with keyframe object annotations}}{9}{figure.caption.11}\protected@file@percent }
\newlabel{fig:epic_bb}{{1.7}{9}{Sample consecutive action segments with keyframe object annotations}{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{Action Recognition Challenge}{9}{section*.12}\protected@file@percent }
\newlabel{sec:ep_AR_chall}{{1.1.4}{9}{Action Recognition Challenge}{section*.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{Action Anticipation Challenge}{9}{section*.14}\protected@file@percent }
\newlabel{sec:ep_AA_chall}{{1.1.4}{9}{Action Anticipation Challenge}{section*.14}{}}
\abx@aux@cite{0}{EK100}
\abx@aux@segm{0}{0}{EK100}
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Sample qualitative results from the challenge's baseline of the Action Recognition Task}}{10}{figure.caption.13}\protected@file@percent }
\newlabel{fig:epic_ar_chall}{{1.8}{10}{Sample qualitative results from the challenge's baseline of the Action Recognition Task}{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces Sample qualitative results from the challenge's baseline of the Action Anticipation Task}}{10}{figure.caption.15}\protected@file@percent }
\newlabel{fig:epic_aa_chall}{{1.9}{10}{Sample qualitative results from the challenge's baseline of the Action Anticipation Task}{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{Object Detection Challenge}{10}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.5}Dataset Release}{10}{subsection.1.1.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces Sample qualitative results from the challenge's baseline of the Object Detection Task}}{11}{figure.caption.17}\protected@file@percent }
\newlabel{fig:epic_od_chall}{{1.10}{11}{Sample qualitative results from the challenge's baseline of the Object Detection Task}{figure.caption.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}EPIC-Kitchens 100}{11}{section.1.2}\protected@file@percent }
\newlabel{sec:EK100}{{1.2}{11}{EPIC-Kitchens 100}{section.1.2}{}}
\abx@aux@backref{19}{EK100}{0}{11}{11}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Motivation}{11}{subsection.1.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Data Collection}{12}{subsection.1.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Annotation}{12}{subsection.1.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Narrator}{12}{section*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Transcriber}{12}{section*.20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Parser}{12}{section*.21}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.11}{\ignorespaces Annotation pipeline: \textbf  {a} narrator, \textbf  {b} transcriber \textbf  {c} temporal segment annotator and \textbf  {d} dependency parser. Red arrows show AMT crowdsourcing of annotations.}}{13}{figure.caption.18}\protected@file@percent }
\newlabel{fig:e100_ann}{{1.11}{13}{Annotation pipeline: \textbf {a} narrator, \textbf {b} transcriber \textbf {c} temporal segment annotator and \textbf {d} dependency parser. Red arrows show AMT crowdsourcing of annotations}{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsubsection}{Temporal Annotator}{13}{section*.22}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.4}Quality Improvements}{13}{subsection.1.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.12}{\ignorespaces Comparing non-stop narrations (blue) to 'pause-and-talk' narrations (red). Right: timestsamps (dots) and segments (bars) for two sample sequences. "pause-and-talk" captures all actions including short ones. Black frames depict missed actions.}}{14}{figure.caption.23}\protected@file@percent }
\newlabel{fig:ep100_comp}{{1.12}{14}{Comparing non-stop narrations (blue) to 'pause-and-talk' narrations (red). Right: timestsamps (dots) and segments (bars) for two sample sequences. "pause-and-talk" captures all actions including short ones. Black frames depict missed actions}{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.5}Challenges and Baselines}{14}{subsection.1.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}EPIC-Fields:\textcolor {red}{Lo metto?Anche se non l'abbiamo usato?}}{14}{section.1.3}\protected@file@percent }
\abx@aux@cite{0}{visor35}
\abx@aux@segm{0}{0}{visor35}
\abx@aux@cite{0}{visor5}
\abx@aux@segm{0}{0}{visor5}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Data}{15}{subsection.1.3.1}\protected@file@percent }
\abx@aux@backref{20}{visor35}{0}{15}{15}
\abx@aux@backref{21}{visor5}{0}{15}{15}
\@writefile{toc}{\contentsline {subsubsection}{Motivation.}{15}{section*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Collection}{15}{section*.25}\protected@file@percent }
\abx@aux@cite{0}{nerf}
\abx@aux@segm{0}{0}{nerf}
\@writefile{toc}{\contentsline {subsubsection}{Filtering}{16}{section*.26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Sparse reconstruction}{16}{section*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Dense reconstruction, automated verification, and restart}{16}{section*.28}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Benchmarks, Experiments and Results}{16}{subsection.1.3.2}\protected@file@percent }
\abx@aux@cite{0}{neuraldiff}
\abx@aux@segm{0}{0}{neuraldiff}
\abx@aux@cite{0}{nerfw}
\abx@aux@segm{0}{0}{nerfw}
\abx@aux@cite{0}{Tnerf}
\abx@aux@segm{0}{0}{Tnerf}
\abx@aux@cite{0}{nerfw}
\abx@aux@segm{0}{0}{nerfw}
\abx@aux@cite{0}{Tnerf}
\abx@aux@segm{0}{0}{Tnerf}
\abx@aux@cite{0}{neuraldiff}
\abx@aux@segm{0}{0}{neuraldiff}
\abx@aux@cite{0}{neuraldiff}
\abx@aux@segm{0}{0}{neuraldiff}
\@writefile{toc}{\contentsline {subsubsection}{New-View Synthesis(NVS)}{17}{section*.29}\protected@file@percent }
\abx@aux@backref{22}{nerf}{0}{17}{17}
\abx@aux@backref{23}{neuraldiff}{0}{17}{17}
\abx@aux@backref{24}{nerfw}{0}{17}{17}
\abx@aux@backref{25}{Tnerf}{0}{17}{17}
\abx@aux@cite{0}{MG}
\abx@aux@segm{0}{0}{MG}
\abx@aux@cite{0}{MG}
\abx@aux@segm{0}{0}{MG}
\abx@aux@cite{0}{nerfw}
\abx@aux@segm{0}{0}{nerfw}
\abx@aux@cite{0}{Tnerf}
\abx@aux@segm{0}{0}{Tnerf}
\abx@aux@cite{0}{neuraldiff}
\abx@aux@segm{0}{0}{neuraldiff}
\abx@aux@backref{26}{nerfw}{0}{18}{18}
\abx@aux@backref{27}{Tnerf}{0}{18}{18}
\abx@aux@backref{28}{neuraldiff}{0}{18}{18}
\@writefile{lot}{\contentsline {table}{\numberline {1.2}{\ignorespaces \textbf  {Dynamic New View Synthesis.}Comparison of different neural rendering methods on varying difficult frames. The values reported corresponds to PSNR considering all pixels in each test frame.}}{18}{table.caption.30}\protected@file@percent }
\newlabel{tab:NVS_comp}{{1.2}{18}{\textbf {Dynamic New View Synthesis.}Comparison of different neural rendering methods on varying difficult frames. The values reported corresponds to PSNR considering all pixels in each test frame}{table.caption.30}{}}
\@writefile{toc}{\contentsline {subsubsection}{Unsupervised Dynamic Object Segmentation(UDOS)}{18}{section*.32}\protected@file@percent }
\abx@aux@backref{29}{neuraldiff}{0}{18}{18}
\abx@aux@backref{30}{MG}{0}{18}{18}
\@writefile{lof}{\contentsline {figure}{\numberline {1.13}{\ignorespaces \textbf  {Dynamic New View Synthesis}. I report an example of the output for the three different methods used: NeRF-W, T-NeRF+ and NeuralDiff. We can see how the initial labelling of difficulty for frames was actually accurate as the reconstructions struggle with Hard frames.}}{19}{figure.caption.31}\protected@file@percent }
\newlabel{fig:NVS}{{1.13}{19}{\textbf {Dynamic New View Synthesis}. I report an example of the output for the three different methods used: NeRF-W, T-NeRF+ and NeuralDiff. We can see how the initial labelling of difficulty for frames was actually accurate as the reconstructions struggle with Hard frames}{figure.caption.31}{}}
\@writefile{toc}{\contentsline {subsubsection}{Semi-Supervised Video Object Segmentation(VOS)}{19}{section*.35}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.14}{\ignorespaces \textbf  {UDOS.} Here is reported the comparison of the different methods' output. The 2D based perform very good on dynamic objects, while 3D methods struggle a bit but can detect even semi-static objects.}}{20}{figure.caption.33}\protected@file@percent }
\newlabel{fig:UDOS}{{1.14}{20}{\textbf {UDOS.} Here is reported the comparison of the different methods' output. The 2D based perform very good on dynamic objects, while 3D methods struggle a bit but can detect even semi-static objects}{figure.caption.33}{}}
\abx@aux@backref{31}{MG}{0}{20}{20}
\abx@aux@backref{32}{nerfw}{0}{20}{20}
\abx@aux@backref{33}{Tnerf}{0}{20}{20}
\abx@aux@backref{34}{neuraldiff}{0}{20}{20}
\@writefile{lot}{\contentsline {table}{\numberline {1.3}{\ignorespaces \textbf  {UDOS.} Here I reported the author results for UDOS. The values visible corresponds to the mAP on segmenting semi-static(SS) and dynamic(Dyn) components of the scene.}}{20}{table.caption.34}\protected@file@percent }
\newlabel{tab:UDOS}{{1.3}{20}{\textbf {UDOS.} Here I reported the author results for UDOS. The values visible corresponds to the mAP on segmenting semi-static(SS) and dynamic(Dyn) components of the scene}{table.caption.34}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}VISOR \textcolor {red}{Lo metto?non usato}}{20}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.5}((Ego4D))}{20}{section.1.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.15}{\ignorespaces \textbf  {VOS.} Here is reported the comparison of the two different methods. The 3D method is clearly beter having as output something really close to the groundtruth. The 2D method instead is performing poorly.}}{21}{figure.caption.36}\protected@file@percent }
\newlabel{fig:VOS}{{1.15}{21}{\textbf {VOS.} Here is reported the comparison of the two different methods. The 3D method is clearly beter having as output something really close to the groundtruth. The 2D method instead is performing poorly}{figure.caption.36}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Neural Rendering}{22}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec:Neural}{{2}{22}{((Ego4D))}{chapter.2}{}}
\abx@aux@cite{0}{examplewebsite}
\abx@aux@segm{0}{0}{examplewebsite}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Photogrammetry}{23}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\abx@aux@backref{35}{examplewebsite}{0}{23}{23}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Pinhole Camera}}{23}{figure.caption.37}\protected@file@percent }
\newlabel{fig:pinhole}{{3.1}{23}{Pinhole Camera}{figure.caption.37}{}}
\abx@aux@cite{0}{sfm_matlab}
\abx@aux@segm{0}{0}{sfm_matlab}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Structure from Motion: SfM}{24}{section.3.1}\protected@file@percent }
\abx@aux@backref{36}{sfm_matlab}{0}{24}{24}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Reference systems}}{25}{figure.caption.38}\protected@file@percent }
\newlabel{fig:reference_systems}{{3.2}{25}{Reference systems}{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Basic SfM Scenario}}{25}{figure.caption.39}\protected@file@percent }
\newlabel{fig:sfm_basic}{{3.3}{25}{Basic SfM Scenario}{figure.caption.39}{}}
\abx@aux@cite{0}{open_cv}
\abx@aux@segm{0}{0}{open_cv}
\abx@aux@cite{0}{open_cv}
\abx@aux@segm{0}{0}{open_cv}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Feature Detection and Matching }{26}{subsection.3.1.1}\protected@file@percent }
\abx@aux@cite{0}{open_cv}
\abx@aux@segm{0}{0}{open_cv}
\abx@aux@cite{0}{Lowe04_SIFT}
\abx@aux@segm{0}{0}{Lowe04_SIFT}
\abx@aux@cite{0}{BAY_SURF}
\abx@aux@segm{0}{0}{BAY_SURF}
\abx@aux@cite{0}{Brief}
\abx@aux@segm{0}{0}{Brief}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Feature Detection Example~\blx@tocontentsinit {0}\cite {open_cv}}}{27}{figure.caption.40}\protected@file@percent }
\abx@aux@backref{38}{open_cv}{0}{27}{27}
\newlabel{fig:sfm_opencv}{{3.4}{27}{Feature Detection Example~\cite {open_cv}}{figure.caption.40}{}}
\abx@aux@backref{39}{open_cv}{0}{27}{27}
\abx@aux@backref{40}{Lowe04_SIFT}{0}{27}{27}
\abx@aux@backref{41}{BAY_SURF}{0}{27}{27}
\abx@aux@backref{42}{Brief}{0}{27}{27}
\abx@aux@cite{0}{ORB}
\abx@aux@segm{0}{0}{ORB}
\abx@aux@backref{43}{ORB}{0}{28}{28}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces SIFT features extracted}}{28}{figure.caption.41}\protected@file@percent }
\newlabel{fig:sift}{{3.5}{28}{SIFT features extracted}{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Features correspondence computed using BruteForce Matcher.}}{29}{figure.caption.42}\protected@file@percent }
\newlabel{fig:politoCorresponance}{{3.6}{29}{Features correspondence computed using BruteForce Matcher}{figure.caption.42}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Estimating Fundamental and Essential Matrices}{29}{subsection.3.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Point correspondence geometry. }}{29}{figure.caption.43}\protected@file@percent }
\newlabel{fig:epipolar}{{3.7}{29}{Point correspondence geometry}{figure.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces \relax }}{30}{figure.caption.44}\protected@file@percent }
\newlabel{fig:EstimateMatrices}{{3.8}{30}{\relax }{figure.caption.44}{}}
\newlabel{eq:E1}{{3.1}{30}{Estimating Fundamental and Essential Matrices}{equation.3.1.1}{}}
\newlabel{eq:EssentialMatrix}{{3.4}{31}{Estimating Fundamental and Essential Matrices}{equation.3.1.4}{}}
\newlabel{eq:Fund}{{3.7}{31}{Estimating Fundamental and Essential Matrices}{equation.3.1.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Estimating Camera Pose from Essential Matrix}{31}{subsection.3.1.3}\protected@file@percent }
\newlabel{eq:t}{{3.9}{31}{Estimating Camera Pose from Essential Matrix}{equation.3.1.9}{}}
\newlabel{eq:tR}{{3.10}{31}{Estimating Camera Pose from Essential Matrix}{equation.3.1.10}{}}
\newlabel{eq:W}{{3.11}{31}{Estimating Camera Pose from Essential Matrix}{equation.3.1.11}{}}
\abx@aux@cite{0}{colmap}
\abx@aux@segm{0}{0}{colmap}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}Multi-view Structure from Motion}{32}{subsection.3.1.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Multiple View Scenario. }}{32}{figure.caption.45}\protected@file@percent }
\newlabel{fig:multiview}{{3.9}{32}{Multiple View Scenario}{figure.caption.45}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.5}COLMAP}{32}{subsection.3.1.5}\protected@file@percent }
\newlabel{sec:col}{{3.1.5}{32}{COLMAP}{subsection.3.1.5}{}}
\abx@aux@cite{0}{schoenberger2016sfm}
\abx@aux@segm{0}{0}{schoenberger2016sfm}
\abx@aux@cite{0}{schoenberger2016mvs}
\abx@aux@segm{0}{0}{schoenberger2016mvs}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Building Rome in one day}}{33}{figure.caption.46}\protected@file@percent }
\newlabel{fig:colmap_image}{{3.10}{33}{Building Rome in one day}{figure.caption.46}{}}
\abx@aux@backref{44}{colmap}{0}{33}{33}
\abx@aux@backref{45}{schoenberger2016sfm}{0}{33}{33}
\abx@aux@backref{46}{schoenberger2016mvs}{0}{33}{33}
\@writefile{toc}{\contentsline {subsubsection}{Usage}{33}{section*.47}\protected@file@percent }
\newlabel{lst:bash}{{3.1}{33}{Automatic COLMAP Reconstruction}{lstlisting.3.1}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.1}{\ignorespaces Automatic COLMAP Reconstruction}}{33}{lstlisting.3.1}\protected@file@percent }
\newlabel{lst:col}{{3.2}{34}{COLMAP Single Commands}{lstlisting.3.2}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.2}{\ignorespaces COLMAP Single Commands}}{34}{lstlisting.3.2}\protected@file@percent }
\abx@aux@cite{0}{Ranftl2021}
\abx@aux@segm{0}{0}{Ranftl2021}
\abx@aux@cite{0}{Ranftl2021}
\abx@aux@segm{0}{0}{Ranftl2021}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.6}Monocular Depth Estimation}{35}{subsection.3.1.6}\protected@file@percent }
\abx@aux@backref{47}{Ranftl2021}{0}{35}{35}
\abx@aux@cite{0}{Ranftl2022}
\abx@aux@segm{0}{0}{Ranftl2022}
\abx@aux@cite{0}{Ranftl2022}
\abx@aux@segm{0}{0}{Ranftl2022}
\abx@aux@cite{0}{Ranftl2022}
\abx@aux@segm{0}{0}{Ranftl2022}
\abx@aux@backref{48}{Ranftl2021}{0}{36}{36}
\abx@aux@backref{49}{Ranftl2022}{0}{36}{36}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Monocular datasets}}{36}{figure.caption.48}\protected@file@percent }
\newlabel{fig:datasets_mono}{{3.11}{36}{Monocular datasets}{figure.caption.48}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Your Table Caption Here}}{36}{table.caption.50}\protected@file@percent }
\newlabel{tab:mytable}{{3.1}{36}{Your Table Caption Here}{table.caption.50}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces Top: input images. Middle: Inverse depth maps predicted by the presented approach. Bottom: corresponding point clouds rendered from a novel view-point.(Taken from \blx@tocontentsinit {0}\cite {Ranftl2022})}}{37}{figure.caption.49}\protected@file@percent }
\abx@aux@backref{51}{Ranftl2022}{0}{37}{37}
\newlabel{fig:mono}{{3.12}{37}{Top: input images. Middle: Inverse depth maps predicted by the presented approach. Bottom: corresponding point clouds rendered from a novel view-point.(Taken from \cite {Ranftl2022})}{figure.caption.49}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Your Table Caption Here}}{37}{table.caption.51}\protected@file@percent }
\newlabel{tab:mytable}{{3.2}{37}{Your Table Caption Here}{table.caption.51}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces Your Table Caption Here}}{38}{table.caption.52}\protected@file@percent }
\newlabel{tab:mytable}{{3.3}{38}{Your Table Caption Here}{table.caption.52}{}}
\@writefile{toc}{\contentsline {part}{II\hspace  {1em}Da Sistemare}{39}{part.2}\protected@file@percent }
\abx@aux@cite{0}{neuraldiff}
\abx@aux@segm{0}{0}{neuraldiff}
\newlabel{sec:Sistemare}{{II}{40}{Da Sistemare}{part.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Metrics}{40}{section.3.2}\protected@file@percent }
\newlabel{sec:Metrics}{{3.2}{40}{Metrics}{section.3.2}{}}
\abx@aux@backref{52}{neuraldiff}{0}{40}{40}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}PSNR:Peak signal-to-noise ratio}{40}{subsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}AP:Average Precision}{40}{subsection.3.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces Example of Precision-recall curve.We can see how the bottom line model represents the worst a model can perform, e.g. predict every sample as it is coming from the same class,if the dataset is balanced. A better model would \textit  {tend} to the upper-right corner, which instead represents the best possible model, a model that have maximum precision and recall.}}{41}{figure.caption.53}\protected@file@percent }
\newlabel{fig:auc}{{3.13}{41}{Example of Precision-recall curve.We can see how the bottom line model represents the worst a model can perform, e.g. predict every sample as it is coming from the same class,if the dataset is balanced. A better model would \textit {tend} to the upper-right corner, which instead represents the best possible model, a model that have maximum precision and recall}{figure.caption.53}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.4}{\ignorespaces Your Table Caption Here}}{42}{table.caption.54}\protected@file@percent }
\newlabel{tab:mytable}{{3.4}{42}{Your Table Caption Here}{table.caption.54}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.5}{\ignorespaces Your Table Caption Here}}{42}{table.caption.55}\protected@file@percent }
\newlabel{tab:mytable}{{3.5}{42}{Your Table Caption Here}{table.caption.55}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.6}{\ignorespaces Your Table Caption Here}}{43}{table.caption.56}\protected@file@percent }
\newlabel{tab:mytable}{{3.6}{43}{Your Table Caption Here}{table.caption.56}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Galileo}{44}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec:appendix_galileo}{{A}{44}{AP:Average Precision}{appendix.A}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Math Notation}{45}{appendix.B}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:MathNotation}{{B}{45}{AP:Average Precision}{appendix.B}{}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{46}{appendix.B}\protected@file@percent }
\abx@aux@read@bbl@mdfivesum{4AD5DCC7E9E0DE022A1B6E0A55D3B85C}
\abx@aux@defaultrefcontext{0}{EPICKITCHENS}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{residualImage}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{fasterRCNN}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{captioning}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{vqa}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{pascalImage}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{imagenet}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{COCO}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{ADE20K}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{somethingSomething}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{yt}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{movieBench}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{movieQA}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{vlogs}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{charades}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{EK100}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{visor35}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{visor5}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{nerf}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{neuraldiff}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{nerfw}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Tnerf}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{MG}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{examplewebsite}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{sfm_matlab}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{open_cv}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Lowe04_SIFT}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{BAY_SURF}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Brief}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{ORB}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{colmap}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{schoenberger2016sfm}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{schoenberger2016mvs}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Ranftl2021}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Ranftl2022}{none/global//global/global}
\gdef\svg@ink@ver@settings{{\m@ne }{inkscape}{\m@ne }}
\gdef \@abspage@last{61}
